{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Vs6mH5djCLDt","QvMk8LYVChQM","TBoSaClRr9pX","T9Ko3f69yIrY","Q663oP9bF1_-","TAttt5L5F5x7"],"mount_file_id":"117lmsqgk76gbo3uyVRfgCWOQrauzKMPP","authorship_tag":"ABX9TyNG2oQ0IpaBAWGXdX1FbXZe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#Move to Folder"],"metadata":{"id":"Vs6mH5djCLDt"}},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4xzlOGV2BrR3","executionInfo":{"status":"ok","timestamp":1668354705886,"user_tz":-330,"elapsed":1474,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"ff9920c0-e7e3-4ff1-9431-352d9f86d555"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["bidafc2id.pickle  bidafvalid.pkl    evaluate.py  preprocess.py\n","bidafglove.npy\t  bidafw2id.pickle  GloVe\t __pycache__\n","bidaftrain.pkl\t  data\t\t    main.py\n"]}]},{"cell_type":"code","source":["%cd drive/MyDrive/Project/squad/bidaf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ha6YvPG_B5DV","executionInfo":{"status":"ok","timestamp":1668617673910,"user_tz":-330,"elapsed":4,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"3dc57531-c63f-47f5-c7d3-c0b5e8912ceb"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive/Project/squad/bidaf'\n","/content/drive/MyDrive/Project/squad\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import re, os, string, typing, gc, json\n","import spacy\n","from collections import Counter\n","\n","from torch import nn\n","import torch\n","import numpy as np\n","import pandas as pd\n","import pickle, time\n","import re, os, string, typing, gc, json\n","import torch.nn.functional as F\n","import spacy\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","nlp = spacy.blank('en')\n","# from preprocess import *\n","%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"qDQ39QXcCe15","executionInfo":{"status":"ok","timestamp":1668616840962,"user_tz":-330,"elapsed":11591,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ha5yTmqZrMuP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"i4rmo-NPrMse"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cnxr7J1LrMqZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TiM06oV0rMkF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Preprocessing"],"metadata":{"id":"QvMk8LYVChQM"}},{"cell_type":"code","source":["def load_json(path):\n","    '''\n","    Loads the JSON file of the Squad dataset.\n","    Returns the json object of the dataset.\n","    '''\n","    with open(path, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","        \n","    print(\"Length of data: \", len(data['data']))\n","    print(\"Data Keys: \", data['data'][0].keys())\n","    print(\"Title: \", data['data'][0]['title'])\n","    \n","    return data"],"metadata":{"id":"0urnp7yIf9n7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def parse_data(data:dict)->list:\n","    '''\n","    Parses the JSON file of Squad dataset by looping through the\n","    keys and values and returns a list of dictionaries with\n","    context, query and label triplets being the keys of each dict.\n","    '''\n","    data = data['data']\n","    qa_list = []\n","    gk = []\n","    dk = []\n","\n","    for paragraphs in data:\n","\n","        for para in paragraphs['paragraphs']:\n","            context = para['context']\n","            if \"§\" in context.lower():\n","                if context not in gk:\n","                    print(context)\n","                    gk.append(context)\n","                continue\n","\n","            for qa in para['qas']:\n","                \n","                id = qa['id']\n","                question = qa['question']\n","                if \"§\" in question.lower():\n","                    if question not in dk:\n","                        print(\"q\")\n","                        print(question)\n","                        dk.append(question)\n","                    continue\n","                \n","                \n","                for ans in qa['answers']:\n","                    answer = ans['text']\n","                    ans_start = ans['answer_start']\n","                    ans_end = ans_start + len(answer)\n","                    \n","                    qa_dict = {}\n","                    qa_dict['id'] = id\n","                    qa_dict['context'] = context\n","                    qa_dict['question'] = question\n","                    qa_dict['label'] = [ans_start, ans_end]\n","\n","                    qa_dict['answer'] = answer\n","                    qa_list.append(qa_dict)    \n","\n","    \n","    return qa_list"],"metadata":{"id":"08CLBFbwhNVk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gather_text_for_vocab(dfs:list):\n","    '''\n","    Gathers text from contexts and questions to build a vocabulary.\n","    \n","    :param dfs: list of dataframes of SQUAD dataset.\n","    :returns: list of contexts and questions\n","    '''\n","    \n","    text = []\n","    total = 0\n","    for df in dfs:\n","        unique_contexts = list(df.context.unique())\n","        unique_questions = list(df.question.unique())\n","        total += df.context.nunique() + df.question.nunique()\n","        text.extend(unique_contexts + unique_questions)\n","    \n","    assert len(text) == total\n","    \n","    return text"],"metadata":{"id":"valtB5uyiYU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_word_vocab(vocab_text):\n","    '''\n","    Builds a word-level vocabulary from the given text.\n","    \n","    :param list vocab_text: list of contexts and questions\n","    :returns \n","        dict word2idx: word to index mapping of words\n","        dict idx2word: integer to word mapping\n","        list word_vocab: list of words sorted by frequency\n","    '''\n","    \n","    \n","    words = []\n","    for sent in vocab_text:\n","        for word in nlp(sent, disable=['parser','tagger','ner']):\n","            words.append(word.text)\n","\n","    word_counter = Counter(words)\n","    word_vocab = sorted(word_counter, key=word_counter.get, reverse=True)\n","    print(f\"raw-vocab: {len(word_vocab)}\")\n","    #word_vocab = list(set(word_vocab).intersection(set(glove_words)))\n","    print(f\"glove-vocab: {len(word_vocab)}\")\n","    word_vocab.insert(0, '')\n","    word_vocab.insert(1, '')\n","    print(f\"vocab-length: {len(word_vocab)}\")\n","    word2idx = {word:idx for idx, word in enumerate(word_vocab)}\n","    print(f\"word2idx-length: {len(word2idx)}\")\n","    idx2word = {v:k for k,v in word2idx.items()}\n","    \n","    \n","    return word2idx, idx2word, word_vocab\n"],"metadata":{"id":"GdiRpCfyjW0q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_char_vocab(vocab_text):\n","    '''\n","    Builds a character-level vocabulary from the given text.\n","    \n","    :param list vocab_text: list of contexts and questions\n","    :returns \n","        dict char2idx: character to index mapping of words\n","        list char_vocab: list of characters sorted by frequency\n","    '''\n","    \n","    chars = []\n","    for sent in vocab_text:\n","        for ch in sent:\n","            chars.append(ch)\n","\n","    char_counter = Counter(chars)\n","    char_vocab = sorted(char_counter, key=char_counter.get, reverse=True)\n","    print(f\"raw-char-vocab: {len(char_vocab)}\")\n","    high_freq_char = [char for char, count in char_counter.items() if count>=20]\n","    char_vocab = list(set(char_vocab).intersection(set(high_freq_char)))\n","    print(f\"char-vocab-intersect: {len(char_vocab)}\")\n","    char_vocab.insert(0,'')\n","    char_vocab.insert(1,'')\n","    char2idx = {char:idx for idx, char in enumerate(char_vocab)}\n","    print(f\"char2idx-length: {len(char2idx)}\")\n","    \n","    return char2idx, char_vocab"],"metadata":{"id":"Vr8cfv3tmLEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def context_to_ids(text, word2idx):\n","    '''\n","    Converts context text to their respective ids by mapping each word\n","    using word2idx. Input text is tokenized using spacy tokenizer first.\n","    \n","    :param str text: context text to be converted\n","    :returns list context_ids: list of mapped ids\n","    \n","    :raises assertion error: sanity check\n","    \n","    '''\n","\n","    context_tokens = [w.text for w in nlp(text, disable=['parser','tagger','ner'])]\n","    context_ids = [word2idx[word] for word in context_tokens]\n","    \n","    assert len(context_ids) == len(context_tokens)\n","    return context_ids\n","    \n","def question_to_ids(text, word2idx):\n","    '''\n","    Converts question text to their respective ids by mapping each word\n","    using word2idx. Input text is tokenized using spacy tokenizer first.\n","    \n","    :param str text: question text to be converted\n","    :returns list context_ids: list of mapped ids\n","    \n","    :raises assertion error: sanity check\n","    \n","    '''\n","\n","    question_tokens = [w.text for w in nlp(text, disable=['parser','tagger','ner'])]\n","    question_ids = [word2idx[word] for word in question_tokens]\n","    \n","    assert len(question_ids) == len(question_tokens)\n","    return question_ids"],"metadata":{"id":"ztbYgCS6nPL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pg = \"n 1992 he started working at the Eindhoven University of Technology as an assistant professor for the department of Mathematics and Computing Science, where he headed the Specification and Modeling of Information systems (SMIS) research group. 2000 to 2003 he became a part-time full professor at the Computing Science department. And from 2000 to 2006 he was head of the Information Systems department at the Technology Management department of TU/e. Since 2006 he is full professor at the Department of Mathematics & Computer Science of the Eindhoven University of Technology. He also has a part-time appointment in the BPM group of Queensland University of Technology (QUT)\""],"metadata":{"id":"GsBjkNjXpKEo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s, e = zip(*[(word.idx, word.idx+len(word.text)) for word in nlp(pg)])"],"metadata":{"id":"opbZ3dYEncFl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_indices(df, idx2word):\n","    '''\n","    Performs the tests mentioned above. This method also gets the start and end of the answers\n","    with respect to the context_ids for each example.\n","    \n","    :param dataframe df: SQUAD df\n","    :returns\n","        list start_value_error: example idx where the start idx is not found in the start spans\n","                                of the text\n","        list end_value_error: example idx where the end idx is not found in the end spans\n","                              of the text\n","        list assert_error: examples that fail assertion errors. A majority are due to the above errors\n","        \n","    '''\n","\n","    start_value_error = []\n","    end_value_error = []\n","    assert_error = []\n","    for index, row in df.iterrows():\n","\n","        answer_tokens = [w.text for w in nlp(row['answer'], disable=['parser','tagger','ner'])]\n","\n","        start_token = answer_tokens[0]\n","        end_token = answer_tokens[-1]\n","        \n","        context_span  = [(word.idx, word.idx + len(word.text)) \n","                         for word in nlp(row['context'], disable=['parser','tagger','ner'])]\n","\n","        starts, ends = zip(*context_span)\n","\n","        answer_start, answer_end = row['label']\n","\n","        try:\n","            start_idx = starts.index(answer_start)\n","        except:\n","            start_value_error.append(index)\n","        try:\n","            end_idx  = ends.index(answer_end)\n","        except:\n","            end_value_error.append(index)\n","\n","        try:\n","            assert idx2word[row['context_ids'][start_idx]] == answer_tokens[0]\n","            assert idx2word[row['context_ids'][end_idx]] == answer_tokens[-1]\n","        except:\n","            assert_error.append(index)\n","\n","\n","    return start_value_error, end_value_error, assert_error"],"metadata":{"id":"guBM_1FGpXvJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_error_indices(df, idx2word):\n","    '''\n","    Gets error indices from the method above and returns a \n","    set of those indices.\n","    '''\n","    \n","    start_value_error, end_value_error, assert_error = test_indices(df, idx2word)\n","    err_idx = start_value_error + end_value_error + assert_error\n","    err_idx = set(err_idx)\n","    print(f\"Error indices: {len(err_idx)}\")\n","    \n","    return err_idx"],"metadata":{"id":"7Gy6JCqrp3SG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def index_answer(row, idx2word):\n","    '''\n","    Takes in a row of the dataframe or one training example and\n","    returns a tuple of start and end positions of answer by calculating \n","    spans.\n","    '''\n","    \n","    context_span = [(word.idx, word.idx + len(word.text)) for word in nlp(row.context, disable=['parser','tagger','ner'])]\n","    starts, ends = zip(*context_span)\n","    \n","    answer_start, answer_end = row.label\n","    start_idx = starts.index(answer_start)\n"," \n","    end_idx  = ends.index(answer_end)\n","    \n","    ans_toks = [w.text for w in nlp(row.answer,disable=['parser','tagger','ner'])]\n","    ans_start = ans_toks[0]\n","    ans_end = ans_toks[-1]\n","    assert idx2word[row.context_ids[start_idx]] == ans_start\n","    assert idx2word[row.context_ids[end_idx]] == ans_end\n","    \n","    return [start_idx, end_idx]"],"metadata":{"id":"nZYw6JJxrELp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Preprocess Data"],"metadata":{"id":"TBoSaClRr9pX"}},{"cell_type":"code","source":["train_data = load_json('./data/squad_train.json')\n","valid_data = load_json('./data/squad_dev.json')\n","\n","# parse the json structure to return the data as a list of dictionaries\n","\n","train_list = parse_data(train_data)\n","valid_list = parse_data(valid_data)\n","print('--------------------------')\n","\n","print('Train list len: ',len(train_list))\n","print('Valid list len: ',len(valid_list))\n","\n","# converting the lists into dataframes\n","\n","train_df = pd.DataFrame(train_list)\n","valid_df = pd.DataFrame(valid_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzJDeUGysPYF","executionInfo":{"status":"ok","timestamp":1668478796654,"user_tz":-330,"elapsed":3858,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"ee6e2f85-322f-42cb-8f41-9b7dd313f323"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of data:  442\n","Data Keys:  dict_keys(['title', 'paragraphs'])\n","Title:  University_of_Notre_Dame\n","Length of data:  48\n","Data Keys:  dict_keys(['title', 'paragraphs'])\n","Title:  Super_Bowl_50\n","Congress often writes legislation to restrain executive officials to the performance of their duties, as laid out by the laws Congress passes. In INS v. Chadha (1983), the Supreme Court decided (a) The prescription for legislative action in Art. I, § 1—requiring all legislative powers to be vested in a Congress consisting of a Senate and a House of Representatives—and § 7—requiring every bill passed by the House and Senate, before becoming law, to be presented to the president, and, if he disapproves, to be repassed by two-thirds of the Senate and House—represents the Framers' decision that the legislative power of the Federal Government be exercised in accord with a single, finely wrought and exhaustively considered procedure. This procedure is an integral part of the constitutional design for the separation of powers. Further rulings clarified the case; even both Houses acting together cannot override Executive vetos without a 2⁄3 majority. Legislation may always prescribe regulations governing executive officers.\n","Prior to 1871, the government of the United States regularly entered into treaties with Native Americans but the Indian Appropriations Act of March 3, 1871 (ch. 120, 16 Stat. 563) had a rider (25 U.S.C. § 71) attached that effectively ended the President’s treaty making by providing that no Indian nation or tribe shall be acknowledged as an independent nation, tribe, or power with whom the United States may contract by treaty. The federal government continued to provide similar contractual relations with the Indian tribes after 1871 by agreements, statutes, and executive orders.\n","The Constitution of the United States of America provides that the United States Congress has the power \"To coin money\". Laws implementing this power are currently codified at 31 U.S.C. § 5112. Section 5112 prescribes the forms, in which the United States dollars should be issued. These coins are both designated in Section 5112 as \"legal tender\" in payment of debts. The Sacagawea dollar is one example of the copper alloy dollar. The pure silver dollar is known as the American Silver Eagle. Section 5112 also provides for the minting and issuance of other coins, which have values ranging from one cent to 50 dollars. These other coins are more fully described in Coins of the United States dollar.\n","The code itself was patterned so that most control codes were together, and all graphic codes were together, for ease of identification. The first two columns (32 positions) were reserved for control characters.:220, 236 § 8,9) The \"space\" character had to come before graphics to make sorting easier, so it became position 20hex;:237 § 10 for the same reason, many special signs commonly used as separators were placed before digits. The committee decided it was important to support uppercase 64-character alphabets, and chose to pattern ASCII so it could be reduced easily to a usable 64-character set of graphic codes,:228, 237 § 14 as was done in the DEC SIXBIT code. Lowercase letters were therefore not interleaved with uppercase. To keep options available for lowercase letters and other graphics, the special and numeric codes were arranged before the letters, and the letter A was placed in position 41hex to match the draft of the corresponding British standard.:238 § 18 The digits 0–9 were arranged so they correspond to values in binary prefixed with 011, making conversion with binary-coded decimal straightforward.\n","The committee debated the possibility of a shift function (like in ITA2), which would allow more than 64 codes to be represented by a six-bit code. In a shifted code, some character codes determine choices between options for the following character codes. It allows compact encoding, but is less reliable for data transmission as an error in transmitting the shift code typically makes a long part of the transmission unreadable. The standards committee decided against shifting, and so ASCII required at least a seven-bit code.:215, 236 § 4\n","The committee considered an eight-bit code, since eight bits (octets) would allow two four-bit patterns to efficiently encode two digits with binary-coded decimal. However, it would require all data transmission to send eight bits when seven could suffice. The committee voted to use a seven-bit code to minimize costs associated with data transmission. Since perforated tape at the time could record eight bits in one position, it also allowed for a parity bit for error checking if desired.:217, 236 § 5 Eight-bit machines (with octets as the native data type) that did not use parity checking typically set the eighth bit to 0.\n","Under the Antiterrorism and Effective Death Penalty Act of 1996, a state prisoner is ordinarily only allowed one suit for habeas corpus in federal court. If the federal courts refuse to issue a writ of habeas corpus, an execution date may be set. In recent times, however, prisoners have postponed execution through a final round of federal litigation using the Civil Rights Act of 1871 — codified at 42 U.S.C. § 1983 — which allows people to bring lawsuits against state actors to protect their federal constitutional and statutory rights.\n","Present-day statutes from across the nation use the same words and phrases, requiring modern executions to take place within a wall or enclosure to exclude public view. Connecticut General Statute § 54–100 requires death sentences to be conducted in an \"enclosure\" which \"shall be so constructed as to exclude public view.\" Kentucky Revised Statute 431.220 and Missouri Revised Statute § 546.730 contain substantially identical language. New Mexico's former death penalty, since repealed, see N.M. Stat. § 31-14-12, required executions be conducted in a \"room or place enclosed from public view.\" Similarly, a dormant Massachusetts law, see Mass. Gen. Law ch. 279 § 60, required executions to take place \"within an enclosure or building.\" North Carolina General Statute § 15-188 requires death sentences to be executed \"within the walls\" of the penitentiary, as do Oklahoma Statute Title 22 § 1015 and Montana Code § 46-19-103. Ohio Revised Code § 2949.22 requires that \"[t]he enclosure shall exclude public view.\" Similarly, Tennessee Code § 40-23-116 requires \"an enclosure\" for \"strict seclusion and privacy.\" United States Code Title 18 § 3596 and the Code of Federal Regulations 28 CFR 26.4 limit the witnesses permitted at federal executions.\n","The first criminal provision in U.S. copyright law was added in 1897, which established a misdemeanor penalty for \"unlawful performances and representations of copyrighted dramatic and musical compositions\" if the violation had been \"willful and for profit.\" Criminal copyright infringement requires that the infringer acted \"for the purpose of commercial advantage or private financial gain.\" 17 U.S.C. § 506. To establish criminal liability, the prosecutor must first show the basic elements of copyright infringement: ownership of a valid copyright, and the violation of one or more of the copyright holder's exclusive rights. The government must then establish that defendant willfully infringed or, in other words, possessed the necessary mens rea. Misdemeanor infringement has a very low threshold in terms of number of copies and the value of the infringed works.\n","Trade secret misappropriation is different from violations of other intellectual property laws, since by definition trade secrets are secret, while patents and registered copyrights and trademarks are publicly available. In the United States, trade secrets are protected under state law, and states have nearly universally adopted the Uniform Trade Secrets Act. The United States also has federal law in the form of the Economic Espionage Act of 1996 (18 U.S.C. §§ 1831–1839), which makes the theft or misappropriation of a trade secret a federal crime. This law contains two provisions criminalizing two sorts of activity. The first, 18 U.S.C. § 1831(a), criminalizes the theft of trade secrets to benefit foreign powers. The second, 18 U.S.C. § 1832, criminalizes their theft for commercial or economic purposes. (The statutory penalties are different for the two offenses.) In Commonwealth common law jurisdictions, confidentiality and trade secrets are regarded as an equitable right rather than a property right but penalties for theft are roughly the same as the United States.[citation needed]\n","Idealist notions took a strong hold among physicists of the early 20th century confronted with the paradoxes of quantum physics and the theory of relativity. In The Grammar of Science, Preface to the 2nd Edition, 1900, Karl Pearson wrote, \"There are many signs that a sound idealism is surely replacing, as a basis for natural philosophy, the crude materialism of the older physicists.\" This book influenced Einstein's regard for the importance of the observer in scientific measurements[citation needed]. In § 5 of that book, Pearson asserted that \"...science is in reality a classification and analysis of the contents of the mind....\" Also, \"...the field of science is much more consciousness than an external world.\"\n","The Endangered Species Act of 1973 (ESA; 16 U.S.C. § 1531 et seq.) is one of the few dozens of United States environmental laws passed in the 1970s, and serves as the enacting legislation to carry out the provisions outlined in The Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES). The ESA was signed into law by President Richard Nixon on December 28, 1973, it was designed to protect critically imperiled species from extinction as a \"consequence of economic growth and development untempered by adequate concern and conservation.\" The U.S. Supreme Court found that \"the plain intent of Congress in enacting\" the ESA \"was to halt and reverse the trend toward species extinction, whatever the cost.\" The Act is administered by two federal agencies, the United States Fish and Wildlife Service (FWS) and the National Oceanic and Atmospheric Administration (NOAA).\n","The \"Safe Harbor\" agreement is a voluntary agreement between the private landowner and FWS. The landowner agrees to alter the property to benefit or even attract a listed or proposed species in exchange for assurances that the FWS will permit future \"takes\" above a pre-determined level. The policy relies on the \"enhancement of survival\" provision of Section §1539(a)(1)(A). A landowner can have either a \"Safe Harbor\" agreement or an Incidental Take Permit, or both. The policy was developed by the Clinton Administration in 1999.\n","First, if a Directive's deadline for implementation is not met, the member state cannot enforce conflicting laws, and a citizen may rely on the Directive in such an action (so called \"vertical\" direct effect). So, in Pubblico Ministero v Ratti because the Italian government had failed to implement a Directive 73/173/EEC on packaging and labelling solvents by the deadline, it was estopped from enforcing a conflicting national law from 1963 against Mr Ratti's solvent and varnish business. A member state could \"not rely, as against individuals, on its own failure to perform the obligations which the Directive entails.\" Second, a citizen or company can invoke a Directive, not just in a dispute with a public authority, but in a dispute with another citizen or company. So, in CIA Security v Signalson and Securitel the Court of Justice held that a business called CIA Security could defend itself from allegations by competitors that it had not complied with a Belgian decree from 1991 about alarm systems, on the basis that it had not been notified to the Commission as a Directive required. Third, if a Directive gives expression to a \"general principle\" of EU law, it can be invoked between private non-state parties before its deadline for implementation. This follows from Kücükdeveci v Swedex GmbH & Co KG where the German Civil Code §622 stated that the years people worked under the age of 25 would not count towards the increasing statutory notice before dismissal. Ms Kücükdeveci worked for 10 years, from age 18 to 28, for Swedex GmbH & Co KG before her dismissal. She claimed that the law not counting her years under age 25 was unlawful age discrimination under the Employment Equality Framework Directive. The Court of Justice held that the Directive could be relied on by her because equality was also a general principle of EU law. Third, if the defendant is an emanation of the state, even if not central government, it can still be bound by Directives. In Foster v British Gas plc the Court of Justice held that Mrs Foster was entitled to bring a sex discrimination claim against her employer, British Gas plc, which made women retire at age 60 and men at 65, if (1) pursuant to a state measure, (2) it provided a public service, and (3) had special powers. This could also be true if the enterprise is privatised, as it was held with a water company that was responsible for basic water provision.\n","--------------------------\n","Train list len:  87541\n","Valid list len:  34711\n"]}]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"id":"CqcpDTZDsY-F","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1668478807629,"user_tz":-330,"elapsed":427,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"a8d17642-0009-4ac2-a707-f862546fa9cc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                         id  \\\n","0  5733be284776f41900661182   \n","1  5733be284776f4190066117f   \n","2  5733be284776f41900661180   \n","3  5733be284776f41900661181   \n","4  5733be284776f4190066117e   \n","\n","                                             context  \\\n","0  Architecturally, the school has a Catholic cha...   \n","1  Architecturally, the school has a Catholic cha...   \n","2  Architecturally, the school has a Catholic cha...   \n","3  Architecturally, the school has a Catholic cha...   \n","4  Architecturally, the school has a Catholic cha...   \n","\n","                                            question       label  \\\n","0  To whom did the Virgin Mary allegedly appear i...  [515, 541]   \n","1  What is in front of the Notre Dame Main Building?  [188, 213]   \n","2  The Basilica of the Sacred heart at Notre Dame...  [279, 296]   \n","3                  What is the Grotto at Notre Dame?  [381, 420]   \n","4  What sits on top of the Main Building at Notre...   [92, 126]   \n","\n","                                    answer  \n","0               Saint Bernadette Soubirous  \n","1                a copper statue of Christ  \n","2                        the Main Building  \n","3  a Marian place of prayer and reflection  \n","4       a golden statue of the Virgin Mary  "],"text/html":["\n","  <div id=\"df-7b4d7d18-218a-4b95-a727-0b08ec7709f4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>label</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5733be284776f41900661182</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>To whom did the Virgin Mary allegedly appear i...</td>\n","      <td>[515, 541]</td>\n","      <td>Saint Bernadette Soubirous</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5733be284776f4190066117f</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is in front of the Notre Dame Main Building?</td>\n","      <td>[188, 213]</td>\n","      <td>a copper statue of Christ</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5733be284776f41900661180</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n","      <td>[279, 296]</td>\n","      <td>the Main Building</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5733be284776f41900661181</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is the Grotto at Notre Dame?</td>\n","      <td>[381, 420]</td>\n","      <td>a Marian place of prayer and reflection</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5733be284776f4190066117e</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What sits on top of the Main Building at Notre...</td>\n","      <td>[92, 126]</td>\n","      <td>a golden statue of the Virgin Mary</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b4d7d18-218a-4b95-a727-0b08ec7709f4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7b4d7d18-218a-4b95-a727-0b08ec7709f4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7b4d7d18-218a-4b95-a727-0b08ec7709f4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["def preprocess_df(df):\n","    \n","    def to_lower(text):\n","        return text.lower()\n","\n","    df.context = df.context.apply(to_lower)\n","    df.question = df.question.apply(to_lower)\n","    df.answer = df.answer.apply(to_lower)"],"metadata":{"id":"x5S7OsZEtRCS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocess_df(train_df)\n","preprocess_df(valid_df)\n","\n","train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"-cuJm1t4tlSU","executionInfo":{"status":"ok","timestamp":1668478817991,"user_tz":-330,"elapsed":8,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"13a0d944-e329-4937-994b-3945e578684e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                         id  \\\n","0  5733be284776f41900661182   \n","1  5733be284776f4190066117f   \n","2  5733be284776f41900661180   \n","3  5733be284776f41900661181   \n","4  5733be284776f4190066117e   \n","\n","                                             context  \\\n","0  architecturally, the school has a catholic cha...   \n","1  architecturally, the school has a catholic cha...   \n","2  architecturally, the school has a catholic cha...   \n","3  architecturally, the school has a catholic cha...   \n","4  architecturally, the school has a catholic cha...   \n","\n","                                            question       label  \\\n","0  to whom did the virgin mary allegedly appear i...  [515, 541]   \n","1  what is in front of the notre dame main building?  [188, 213]   \n","2  the basilica of the sacred heart at notre dame...  [279, 296]   \n","3                  what is the grotto at notre dame?  [381, 420]   \n","4  what sits on top of the main building at notre...   [92, 126]   \n","\n","                                    answer  \n","0               saint bernadette soubirous  \n","1                a copper statue of christ  \n","2                        the main building  \n","3  a marian place of prayer and reflection  \n","4       a golden statue of the virgin mary  "],"text/html":["\n","  <div id=\"df-d7bd352f-16cf-4d59-ae1c-353d7eb3c5c1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>label</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5733be284776f41900661182</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>to whom did the virgin mary allegedly appear i...</td>\n","      <td>[515, 541]</td>\n","      <td>saint bernadette soubirous</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5733be284776f4190066117f</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>what is in front of the notre dame main building?</td>\n","      <td>[188, 213]</td>\n","      <td>a copper statue of christ</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5733be284776f41900661180</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>the basilica of the sacred heart at notre dame...</td>\n","      <td>[279, 296]</td>\n","      <td>the main building</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5733be284776f41900661181</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>what is the grotto at notre dame?</td>\n","      <td>[381, 420]</td>\n","      <td>a marian place of prayer and reflection</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5733be284776f4190066117e</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>what sits on top of the main building at notre...</td>\n","      <td>[92, 126]</td>\n","      <td>a golden statue of the virgin mary</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7bd352f-16cf-4d59-ae1c-353d7eb3c5c1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d7bd352f-16cf-4d59-ae1c-353d7eb3c5c1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d7bd352f-16cf-4d59-ae1c-353d7eb3c5c1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["vocab_text = gather_text_for_vocab([train_df, valid_df])\n","print(\"Number of sentences in dataset: \", len(vocab_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UmZkboFDtffP","executionInfo":{"status":"ok","timestamp":1668478823347,"user_tz":-330,"elapsed":697,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"0ecc45fd-e6f1-49ce-fbbe-5d5b4aec59a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of sentences in dataset:  118745\n"]}]},{"cell_type":"code","source":["vocab_text[111130]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"kOp86DgStzwN","executionInfo":{"status":"ok","timestamp":1668478824300,"user_tz":-330,"elapsed":3,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"b8852c1e-abe8-4257-de4b-f18f8702025e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"what political party is strongest in melbourne's working class suburbs?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["word2idx, idx2word, word_vocab = build_word_vocab(vocab_text)\n","print(\"----------------------------------\")\n","char2idx, char_vocab = build_char_vocab(vocab_text)"],"metadata":{"id":"KFJRhH4Xt3U1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df['context_ids'] = train_df.context.apply(context_to_ids, word2idx=word2idx)\n","valid_df['context_ids'] = valid_df.context.apply(context_to_ids, word2idx=word2idx)\n","train_df['question_ids'] = train_df.question.apply(question_to_ids, word2idx=word2idx)\n","valid_df['question_ids'] = valid_df.question.apply(question_to_ids, word2idx=word2idx)"],"metadata":{"id":"GyJIV_foum-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"FdAb_RFEu6ZE","executionInfo":{"status":"ok","timestamp":1668361203887,"user_tz":-330,"elapsed":29,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"ba20eca4-752e-4ed3-8fe3-5aaf8ca284fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                         id  \\\n","0  5733be284776f41900661182   \n","1  5733be284776f4190066117f   \n","2  5733be284776f41900661180   \n","3  5733be284776f41900661181   \n","4  5733be284776f4190066117e   \n","\n","                                             context  \\\n","0  architecturally, the school has a catholic cha...   \n","1  architecturally, the school has a catholic cha...   \n","2  architecturally, the school has a catholic cha...   \n","3  architecturally, the school has a catholic cha...   \n","4  architecturally, the school has a catholic cha...   \n","\n","                                            question       label  \\\n","0  to whom did the virgin mary allegedly appear i...  [515, 541]   \n","1  what is in front of the notre dame main building?  [188, 213]   \n","2  the basilica of the sacred heart at notre dame...  [279, 296]   \n","3                  what is the grotto at notre dame?  [381, 420]   \n","4  what sits on top of the main building at notre...   [92, 126]   \n","\n","                                    answer  \\\n","0               saint bernadette soubirous   \n","1                a copper statue of christ   \n","2                        the main building   \n","3  a marian place of prayer and reflection   \n","4       a golden statue of the virgin mary   \n","\n","                                         context_ids  \\\n","0  [16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...   \n","1  [16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...   \n","2  [16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...   \n","3  [16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...   \n","4  [16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...   \n","\n","                                        question_ids  \n","0  [9, 569, 25, 2, 2679, 851, 5993, 1082, 6, 8054...  \n","1   [11, 12, 6, 1202, 4, 2, 1259, 1196, 237, 300, 7]  \n","2  [2, 4546, 4, 2, 3913, 1498, 31, 1259, 1196, 12...  \n","3              [11, 12, 2, 19586, 31, 1259, 1196, 7]  \n","4  [11, 8834, 24, 402, 4, 2, 237, 300, 31, 1259, ...  "],"text/html":["\n","  <div id=\"df-3e7790fe-dbe8-424c-9499-62f54cb6b327\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>label</th>\n","      <th>answer</th>\n","      <th>context_ids</th>\n","      <th>question_ids</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5733be284776f41900661182</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>to whom did the virgin mary allegedly appear i...</td>\n","      <td>[515, 541]</td>\n","      <td>saint bernadette soubirous</td>\n","      <td>[16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...</td>\n","      <td>[9, 569, 25, 2, 2679, 851, 5993, 1082, 6, 8054...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5733be284776f4190066117f</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>what is in front of the notre dame main building?</td>\n","      <td>[188, 213]</td>\n","      <td>a copper statue of christ</td>\n","      <td>[16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...</td>\n","      <td>[11, 12, 6, 1202, 4, 2, 1259, 1196, 237, 300, 7]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5733be284776f41900661180</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>the basilica of the sacred heart at notre dame...</td>\n","      <td>[279, 296]</td>\n","      <td>the main building</td>\n","      <td>[16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...</td>\n","      <td>[2, 4546, 4, 2, 3913, 1498, 31, 1259, 1196, 12...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5733be284776f41900661181</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>what is the grotto at notre dame?</td>\n","      <td>[381, 420]</td>\n","      <td>a marian place of prayer and reflection</td>\n","      <td>[16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...</td>\n","      <td>[11, 12, 2, 19586, 31, 1259, 1196, 7]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5733be284776f4190066117e</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>what sits on top of the main building at notre...</td>\n","      <td>[92, 126]</td>\n","      <td>a golden statue of the virgin mary</td>\n","      <td>[16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...</td>\n","      <td>[11, 8834, 24, 402, 4, 2, 237, 300, 31, 1259, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e7790fe-dbe8-424c-9499-62f54cb6b327')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3e7790fe-dbe8-424c-9499-62f54cb6b327 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3e7790fe-dbe8-424c-9499-62f54cb6b327');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["train_err = get_error_indices(train_df, idx2word)\n","valid_err = get_error_indices(valid_df, idx2word)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LG1ufB8Zvb4e","executionInfo":{"status":"ok","timestamp":1668361246700,"user_tz":-330,"elapsed":42824,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"7d190d6b-2d89-45c5-de44-6d872a3bd49a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error indices: 920\n","Error indices: 349\n"]}]},{"cell_type":"code","source":["train_df.drop(train_err, inplace=True)\n","valid_df.drop(valid_err, inplace=True)"],"metadata":{"id":"19LCpIluwaEJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_label_idx = train_df.apply(index_answer, axis=1, idx2word=idx2word)\n","valid_label_idx = valid_df.apply(index_answer, axis=1, idx2word=idx2word)\n","\n","train_df['label_idx'] = train_label_idx\n","valid_df['label_idx'] = valid_label_idx\n"],"metadata":{"id":"nZ60-Ve7wgz8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"d3n33_yfxC35","executionInfo":{"status":"ok","timestamp":1668361286133,"user_tz":-330,"elapsed":49,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"7b88aaa9-5cd5-4cca-b0c8-a55306c9ff1f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                         id  \\\n","0  5733be284776f41900661182   \n","1  5733be284776f4190066117f   \n","2  5733be284776f41900661180   \n","3  5733be284776f41900661181   \n","4  5733be284776f4190066117e   \n","\n","                                             context  \\\n","0  architecturally, the school has a catholic cha...   \n","1  architecturally, the school has a catholic cha...   \n","2  architecturally, the school has a catholic cha...   \n","3  architecturally, the school has a catholic cha...   \n","4  architecturally, the school has a catholic cha...   \n","\n","                                            question       label  \\\n","0  to whom did the virgin mary allegedly appear i...  [515, 541]   \n","1  what is in front of the notre dame main building?  [188, 213]   \n","2  the basilica of the sacred heart at notre dame...  [279, 296]   \n","3                  what is the grotto at notre dame?  [381, 420]   \n","4  what sits on top of the main building at notre...   [92, 126]   \n","\n","                                    answer  \\\n","0               saint bernadette soubirous   \n","1                a copper statue of christ   \n","2                        the main building   \n","3  a marian place of prayer and reflection   \n","4       a golden statue of the virgin mary   \n","\n","                                         context_ids  \\\n","0  [16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...   \n","1  [16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...   \n","2  [16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...   \n","3  [16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...   \n","4  [16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...   \n","\n","                                        question_ids   label_idx  \n","0  [9, 569, 25, 2, 2679, 851, 5993, 1082, 6, 8054...  [102, 104]  \n","1   [11, 12, 6, 1202, 4, 2, 1259, 1196, 237, 300, 7]    [37, 41]  \n","2  [2, 4546, 4, 2, 3913, 1498, 31, 1259, 1196, 12...    [57, 59]  \n","3              [11, 12, 2, 19586, 31, 1259, 1196, 7]    [76, 82]  \n","4  [11, 8834, 24, 402, 4, 2, 237, 300, 31, 1259, ...    [17, 23]  "],"text/html":["\n","  <div id=\"df-f928cee5-5875-4eff-ae30-31678371bbea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>label</th>\n","      <th>answer</th>\n","      <th>context_ids</th>\n","      <th>question_ids</th>\n","      <th>label_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5733be284776f41900661182</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>to whom did the virgin mary allegedly appear i...</td>\n","      <td>[515, 541]</td>\n","      <td>saint bernadette soubirous</td>\n","      <td>[16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...</td>\n","      <td>[9, 569, 25, 2, 2679, 851, 5993, 1082, 6, 8054...</td>\n","      <td>[102, 104]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5733be284776f4190066117f</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>what is in front of the notre dame main building?</td>\n","      <td>[188, 213]</td>\n","      <td>a copper statue of christ</td>\n","      <td>[16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...</td>\n","      <td>[11, 12, 6, 1202, 4, 2, 1259, 1196, 237, 300, 7]</td>\n","      <td>[37, 41]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5733be284776f41900661180</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>the basilica of the sacred heart at notre dame...</td>\n","      <td>[279, 296]</td>\n","      <td>the main building</td>\n","      <td>[16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...</td>\n","      <td>[2, 4546, 4, 2, 3913, 1498, 31, 1259, 1196, 12...</td>\n","      <td>[57, 59]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5733be284776f41900661181</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>what is the grotto at notre dame?</td>\n","      <td>[381, 420]</td>\n","      <td>a marian place of prayer and reflection</td>\n","      <td>[16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...</td>\n","      <td>[11, 12, 2, 19586, 31, 1259, 1196, 7]</td>\n","      <td>[76, 82]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5733be284776f4190066117e</td>\n","      <td>architecturally, the school has a catholic cha...</td>\n","      <td>what sits on top of the main building at notre...</td>\n","      <td>[92, 126]</td>\n","      <td>a golden statue of the virgin mary</td>\n","      <td>[16255, 3, 2, 133, 40, 10, 544, 793, 5, 8718, ...</td>\n","      <td>[11, 8834, 24, 402, 4, 2, 237, 300, 31, 1259, ...</td>\n","      <td>[17, 23]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f928cee5-5875-4eff-ae30-31678371bbea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f928cee5-5875-4eff-ae30-31678371bbea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f928cee5-5875-4eff-ae30-31678371bbea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["train_df[\"answer\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"S_bj8v5Sx3-G","executionInfo":{"status":"ok","timestamp":1668361286134,"user_tz":-330,"elapsed":26,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"fec98722-f7eb-4c7c-b575-ae5c7f949b98"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'saint bernadette soubirous'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["train_df[\"context\"][0][515:541]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"Js_rho9OxP3W","executionInfo":{"status":"ok","timestamp":1668361286134,"user_tz":-330,"elapsed":23,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"c07c9066-a48c-4329-de78-2187d29b67d3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'saint bernadette soubirous'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":105}]},{"cell_type":"code","source":["nlp(train_df[\"context\"][0])[102:105]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7J5Q95e_xgXD","executionInfo":{"status":"ok","timestamp":1668361286135,"user_tz":-330,"elapsed":22,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"3127c996-d06b-4cc4-c876-0493c810c562"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["saint bernadette soubirous"]},"metadata":{},"execution_count":106}]},{"cell_type":"code","source":["train_df.to_pickle('bidaftrain.pkl')\n","valid_df.to_pickle('bidafvalid.pkl')\n","\n","with open('bidafw2id.pickle','wb') as handle:\n","    pickle.dump(word2idx, handle)\n","\n","with open('bidafc2id.pickle','wb') as handle:\n","    pickle.dump(char2idx, handle)"],"metadata":{"id":"l5cvOpwDxqSl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Data Loader"],"metadata":{"id":"T9Ko3f69yIrY"}},{"cell_type":"code","source":["train_df = pd.read_pickle('bidaftrain.pkl')\n","valid_df = pd.read_pickle('bidafvalid.pkl')\n","\n"],"metadata":{"id":"U5fuNsY50lm7","executionInfo":{"status":"ok","timestamp":1668617701425,"user_tz":-330,"elapsed":5750,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["with open('bidafw2id.pickle','rb') as handle:\n","    word2idx = pickle.load(handle)\n","with open('bidafc2id.pickle','rb') as handle:\n","    char2idx = pickle.load(handle)\n","\n","idx2word = {v:k for k,v in word2idx.items()}"],"metadata":{"id":"SN_iTvuV7RQl","executionInfo":{"status":"ok","timestamp":1668617702018,"user_tz":-330,"elapsed":594,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import torch.utils.data as data\n","\n","class SQuAD:\n","    def __init__(self, data, batch_size):\n","        # super(SQuAD, self).__init__()\n","        \n","        self.batch_size = batch_size\n","        data = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def make_char_vector(self, max_sent_len, max_word_len, sentence):\n","        \n","        char_vec = torch.ones(max_sent_len, max_word_len).type(torch.LongTensor)\n","        \n","        for i, word in enumerate(nlp(sentence, disable=['parser','tagger','ner'])):\n","            for j, ch in enumerate(word.text):\n","                char_vec[i][j] = char2idx.get(ch, 0)\n","        \n","        return char_vec \n","\n","    def get_span(self, text):\n","        \n","        text = nlp(text, disable=['parser','tagger','ner'])\n","        span = [(w.idx, w.idx+len(w.text)) for w in text]\n","\n","        return span\n","\n","    def __iter__(self):\n","        for batch in self.data:\n","            \n","            spans = []\n","            ctx_text = []\n","            answer_text = []\n","            \n","            for ctx in batch.context:\n","                ctx_text.append(ctx)\n","                spans.append(self.get_span(ctx))\n","            \n","            for ans in batch.answer:\n","                answer_text.append(ans)\n","                \n","            \n","            max_context_len = max([len(ctx) for ctx in batch.context_ids])\n","            padded_context = torch.LongTensor(len(batch), max_context_len).fill_(1)\n","            \n","            for i, ctx in enumerate(batch.context_ids):\n","                padded_context[i, :len(ctx)] = torch.LongTensor(ctx)\n","                \n","            max_word_ctx = 0\n","            for context in batch.context:\n","                for word in nlp(context, disable=['parser','tagger','ner']):\n","                    if len(word.text) > max_word_ctx:\n","                        max_word_ctx = len(word.text)\n","            \n","            char_ctx = torch.ones(len(batch), max_context_len, max_word_ctx).type(torch.LongTensor)\n","            for i, context in enumerate(batch.context):\n","                char_ctx[i] = self.make_char_vector(max_context_len, max_word_ctx, context)\n","            \n","            max_question_len = max([len(ques) for ques in batch.question_ids])\n","            padded_question = torch.LongTensor(len(batch), max_question_len).fill_(1)\n","            \n","            for i, ques in enumerate(batch.question_ids):\n","                padded_question[i, :len(ques)] = torch.LongTensor(ques)\n","                \n","            max_word_ques = 0\n","            for question in batch.question:\n","                for word in nlp(question, disable=['parser','tagger','ner']):\n","                    if len(word.text) > max_word_ques:\n","                        max_word_ques = len(word.text)\n","            \n","            char_ques = torch.ones(len(batch), max_question_len, max_word_ques).type(torch.LongTensor)\n","            for i, question in enumerate(batch.question):\n","                char_ques[i] = self.make_char_vector(max_question_len, max_word_ques, question)\n","            \n","            ids = list(batch.id)  \n","            label = torch.LongTensor(list(batch.label_idx))\n","            \n","            yield (padded_context, padded_question, char_ctx, char_ques, label, ctx_text, answer_text, ids)\n","\n","\n","        "],"metadata":{"id":"G7xwUbMFx_C_","executionInfo":{"status":"ok","timestamp":1668617702492,"user_tz":-330,"elapsed":476,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["train_dataset = SQuAD(train_df[:50], 8)\n","valid_dataset = SQuAD(valid_df[-38:-12], 8)"],"metadata":{"id":"Jh55B9m2CiJQ","executionInfo":{"status":"ok","timestamp":1668617702492,"user_tz":-330,"elapsed":3,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["a = next(iter(train_dataset))"],"metadata":{"id":"M1OWHIQJFhnF","executionInfo":{"status":"ok","timestamp":1668617702492,"user_tz":-330,"elapsed":3,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["#BiDAF"],"metadata":{"id":"Q663oP9bF1_-"}},{"cell_type":"markdown","source":["##Word Level Embedding"],"metadata":{"id":"TAttt5L5F5x7"}},{"cell_type":"code","source":["def get_glove_dict():\n","    glove_dict = {}\n","    with open(\"GloVe/glove.840B.300d.txt\", \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            values = line.split(' ')\n","            word = values[0]\n","            vector = np.asarray(values[1:], \"float32\")\n","            glove_dict[word] = vector\n","            \n","    f.close()\n","    \n","    return glove_dict"],"metadata":{"id":"lM9oOZB-Fk7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["glove_dict = get_glove_dict()"],"metadata":{"id":"EyWfw-f3GTOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["glove_dict[\"a\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QQqXwn9GKPV","executionInfo":{"status":"ok","timestamp":1668481600660,"user_tz":-330,"elapsed":818,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"c6cfae66-8375-4a31-dabf-1856b3865fce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 4.3798e-02,  2.4779e-02, -2.0937e-01,  4.9745e-01,  3.6019e-01,\n","       -3.7503e-01, -5.2078e-02, -6.0555e-01,  3.6744e-02,  2.2085e+00,\n","       -2.3389e-01, -6.8360e-02, -2.2355e-01, -5.3989e-02, -1.5198e-01,\n","       -1.7319e-01,  5.3355e-02,  1.6485e+00, -4.7991e-02, -8.5311e-02,\n","       -1.5712e-01, -6.4425e-01, -3.9819e-01,  2.7800e-01,  1.5364e-01,\n","        3.1678e-02,  5.5414e-02,  1.5939e-02,  3.1851e-01, -5.8979e-02,\n","        3.8584e-02,  1.0770e-01,  1.0410e-01, -7.7346e-02,  3.7396e-01,\n","       -2.1482e-01,  3.8320e-01, -2.7737e-01, -1.8352e-01, -8.3838e-01,\n","        3.4124e-01,  5.8164e-01,  1.8543e-01, -3.1028e-01,  1.7666e-01,\n","       -6.9421e-02, -3.4422e-01, -1.3665e-01, -1.0823e-01,  2.3637e-01,\n","       -3.2923e-01,  6.1348e-01,  1.9720e-01,  8.7123e-02,  1.0785e-01,\n","        3.0730e-01,  1.3757e-01,  3.0809e-01,  2.4331e-01, -2.9422e-01,\n","       -9.8214e-03,  5.5675e-01, -4.8880e-02,  9.9468e-02,  3.0543e-01,\n","       -3.7597e-01, -1.9525e-01,  4.6246e-02, -3.6675e-02,  3.4023e-01,\n","        1.4905e-01,  9.7800e-02, -2.6664e-01,  5.6834e-02, -4.3201e-02,\n","       -2.3338e-01,  1.3111e-01, -3.5742e-01, -3.6070e-01,  3.0997e-01,\n","       -1.9727e-01, -1.4320e-01, -1.6747e-01,  4.2435e-04, -1.5120e-01,\n","        6.7562e-02, -3.8644e-01,  2.5349e-02,  2.4918e-01, -2.3955e-01,\n","       -1.5615e-01,  4.9868e-01,  8.2758e-03, -1.9120e-01, -1.4906e-01,\n","        4.8757e-01, -1.5281e-02,  1.0196e-02,  3.7642e-01, -1.9460e-02,\n","       -2.7835e-01,  1.6355e-01, -2.4127e-01, -2.1405e-01, -2.1562e-01,\n","       -7.9697e-01,  3.4321e-01,  9.3209e-02,  7.3977e-02, -2.7147e-01,\n","        2.0539e-01,  1.5061e-01,  2.0734e-02,  1.1267e-01,  2.8714e-02,\n","        2.9670e-01, -2.1267e-01,  4.3214e-01,  1.2788e-01,  2.9249e-01,\n","        1.9056e-01, -2.9113e-01, -1.1382e-01, -3.8242e-02, -2.0290e-01,\n","        1.8301e-01, -1.6661e-01, -2.7116e-01,  1.2685e-03,  7.1704e-02,\n","       -1.8583e-01,  8.9850e-02, -3.9895e-02,  3.9479e-01,  5.3211e-03,\n","       -6.1548e-04, -2.7082e-01, -8.9782e-02, -2.8790e-01, -1.4865e-01,\n","       -1.3746e+00,  1.6515e-01,  2.0598e-01,  1.5252e-01,  3.4723e-02,\n","       -3.8531e-01, -9.4574e-02, -1.9871e-01,  5.0239e-01, -2.8702e-01,\n","       -8.8727e-02,  5.6881e-02,  1.3634e-01,  1.9034e-01, -1.9353e-01,\n","        4.0506e-01, -1.9317e-01,  2.2908e-01,  1.0055e-01, -2.6895e-01,\n","       -3.4727e-02, -8.4010e-02,  5.7806e-02,  1.1076e-02, -4.3349e-02,\n","       -2.6917e-01, -1.9333e-01,  2.2181e-01,  2.6123e-01, -1.1761e-01,\n","        1.0092e-01, -1.5078e-01,  4.7153e-01,  1.1253e-01, -2.6749e-01,\n","       -3.8785e-02, -3.6520e-02, -8.9248e-02, -2.4427e-01, -4.1381e-02,\n","       -2.1785e-02, -3.5738e-01, -6.3409e-02, -5.3983e-01, -1.0112e-02,\n","        4.1238e-04, -9.7049e-02,  4.2628e-01, -2.1349e-01, -4.1055e-01,\n","       -2.4940e-01, -3.3571e-02, -4.9540e-01,  1.5557e-01,  1.9882e-01,\n","        1.0498e-01, -2.4372e-01,  1.1429e-01, -3.9279e-02, -3.6258e-01,\n","        1.0318e-01,  1.2900e-01, -4.1785e-01, -4.1607e-02,  3.3522e-01,\n","        7.3186e-02,  1.3362e-01,  1.0812e-02,  5.2645e-02,  1.8801e-01,\n","       -3.0185e-01,  2.0333e-01, -3.2258e-01, -2.4673e-01,  2.1124e-01,\n","        7.9132e-01, -4.1539e-01,  3.6220e-01,  9.9852e-02, -3.5378e-02,\n","       -4.1900e-02, -1.3851e-01, -6.3255e-02,  1.3635e-01,  9.0863e-02,\n","       -3.9940e-01,  9.9062e-02,  3.2210e-01, -1.2256e-01, -8.5906e-02,\n","       -1.0218e-01,  2.6350e-01, -1.8689e-01, -1.8560e-01, -4.3923e-01,\n","       -3.2500e-01, -1.9910e-01,  1.7831e-01, -2.7283e-01,  3.3473e-01,\n","        8.2382e-02,  1.2825e-01,  3.9275e-01, -3.4929e-02,  1.6148e-01,\n","       -2.6713e-02,  4.0129e-01, -3.9503e-01, -6.4823e-02, -8.9820e-02,\n","       -6.6592e-02, -3.4537e-01,  4.6283e-02,  3.6837e-01, -2.4573e-02,\n","        3.2213e-01,  3.0641e-01, -2.8112e-01,  6.6449e-03,  8.7743e-02,\n","       -3.4170e-02,  6.0373e-01,  4.2120e-01, -7.3349e-02,  2.6682e-01,\n","       -1.5860e-01,  2.3765e-01, -6.2604e-03,  1.5236e-01, -2.3409e-01,\n","        3.1634e-01, -8.7860e-02, -1.5747e-01, -2.4955e-01, -1.8766e-01,\n","       -9.6743e-02, -2.7994e-01, -2.4334e-01,  3.2643e-01,  2.9906e-01,\n","        4.2763e-01,  2.2266e-01, -1.7464e-01, -1.9916e-02, -3.1206e-01,\n","       -3.4009e-01, -1.4993e-01, -2.8818e-01,  1.4750e-01, -4.0503e-02,\n","       -1.0347e-01,  3.3634e-03,  2.1760e-01, -2.0409e-01,  9.2415e-02,\n","        8.0421e-02, -6.1246e-02, -3.0099e-01, -1.4584e-01,  2.8188e-01],\n","      dtype=float32)"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":[],"metadata":{"id":"VlPH641sGZTI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_vocab = list(word2idx.keys())"],"metadata":{"id":"vkAoNbNOJj40"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_weights_matrix(glove_dict):\n","    weights_matrix = np.zeros((len(word_vocab), 300))\n","    words_found = 0\n","    for i, word in enumerate(word_vocab):\n","        try:\n","            weights_matrix[i] = glove_dict[word]\n","            words_found += 1\n","        except:\n","            pass\n","        \n","    return weights_matrix, words_found"],"metadata":{"id":"iaeDv1qBIa-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weights_matrix, words_found = create_weights_matrix(glove_dict)\n","print(\"Words found in the GloVe vocab: \" ,words_found)"],"metadata":{"id":"dwYrEYB-JZ27","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668481720046,"user_tz":-330,"elapsed":9,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"416deb59-51aa-464c-fa51-2b50f47ec472"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Words found in the GloVe vocab:  67397\n"]}]},{"cell_type":"code","source":["len(word_vocab)"],"metadata":{"id":"X04Cr9mRKWrm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668481600665,"user_tz":-330,"elapsed":59,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"f2565857-c7da-46a8-fcb8-84e8afa5feca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["96775"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["weights_matrix.shape"],"metadata":{"id":"Y9B5l5wEKu7p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668481600666,"user_tz":-330,"elapsed":39,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"da2181a4-549b-4100-d989-4034e9a8e753"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(96775, 100)"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["np.save('bidafglove.npy', weights_matrix)"],"metadata":{"id":"6h5vBdARK-2Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Character Level Embedding"],"metadata":{"id":"qU2R5dQtK69_"}},{"cell_type":"code","source":["class CharacterEmbeddingLayer(nn.Module):\n","    def __init__(self, char_vocab_dim, char_emb_dim, num_output_channels, kernel_size, drop_prob=0.2):\n","        super(CharacterEmbeddingLayer, self).__init__()\n","        self.char_emb_dim = char_emb_dim\n","        self.char_embedding = nn.Embedding(char_vocab_dim, char_emb_dim, padding_idx=1)\n","        self.char_convolution = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=kernel_size)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(drop_prob)\n","\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","        x = self.dropout(self.char_embedding(x))\n","        x = x.permute(0, 1, 3, 2)\n","        x = x.view(-1, self.char_emb_dim, x.shape[3])\n","        x = x.unsqueeze(1)\n","\n","        x = self.char_convolution(x)\n","        x = self.relu(x)\n","        x = x.squeeze()\n","        if len(list(x.size())) < 3:\n","            x = x.unsqueeze(2)\n","        x = F.max_pool1d(x, x.shape[2]).squeeze()\n","\n","        x = x.view(batch_size, -1, x.shape[-1])\n","\n","        return(x)"],"metadata":{"id":"qf7mjhGvK2i9","executionInfo":{"status":"ok","timestamp":1668617707692,"user_tz":-330,"elapsed":7,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["##HighWay Networking"],"metadata":{"id":"YBaTOOYjMvN6"}},{"cell_type":"code","source":["class HighwayNetwork(nn.Module):\n","    \n","    def __init__(self, input_dim, num_layers=2):\n","        \n","        super(HighwayNetwork, self).__init__()\n","        \n","        self.num_layers = num_layers\n","        \n","        self.transforms = nn.ModuleList([nn.Linear(input_dim, input_dim) for _ in range(num_layers)])\n","        self.gates = nn.ModuleList([nn.Linear(input_dim, input_dim) for _ in range(num_layers)])\n","        \n","    def forward(self, x):\n","        for gate, transform in zip(self.gates, self.transforms):\n","            # Shapes of g, t, and x are all (batch_size, seq_len, hidden_size)\n","            \n","            g = gate(x)\n","            g = torch.sigmoid(g)\n","            \n","            t = F.relu(transform(x))\n","            \n","            x = g * t + (1 - g) * x\n","\n","        return x"],"metadata":{"id":"0GIDy86QMuxP","executionInfo":{"status":"ok","timestamp":1668617707692,"user_tz":-330,"elapsed":4,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["##Contextual Embeddings"],"metadata":{"id":"NjwGr-AWNiYG"}},{"cell_type":"code","source":["class ContextualEmbeddingLayer(nn.Module):\n","    \n","    def __init__(self, input_dim, hidden_dim):\n","        \n","        super(ContextualEmbeddingLayer, self).__init__()\n","        \n","        self.trans = nn.TransformerEncoderLayer(input_dim, batch_first=True, nhead=8)\n","        self.linear = nn.Sequential(nn.Linear(input_dim, 2*hidden_dim), nn.ReLU())\n","        \n","        self.highway_net = HighwayNetwork(input_dim)\n","        \n","    def forward(self, x):\n","        \n","        highway_out = self.highway_net(x)\n","        # highway_out = [bs, seq_len, input_dim]\n","        \n","        outputs = self.trans(highway_out)\n","        outputs = self.linear(outputs)\n","\n","        # outputs = [bs, seq_len, hidden_dim*2]\n","        \n","        return outputs\n"],"metadata":{"id":"uZcv0llfNbJZ","executionInfo":{"status":"ok","timestamp":1668617958716,"user_tz":-330,"elapsed":3,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["##BiDAF Model"],"metadata":{"id":"cCa81_2ePlmU"}},{"cell_type":"code","source":["class BiDAF(nn.Module):\n","    def __init__(self, char_vocab_dim, emb_dim, char_emb_dim, num_output_channels, \n","                 kernel_size, device):\n","    \n","        super(BiDAF, self).__init__()\n","        self.device = device\n","\n","        self.word_embedding = self.get_glove_embedding()\n","        self.character_embedding = CharacterEmbeddingLayer(char_vocab_dim, char_emb_dim, num_output_channels, kernel_size)\n","        self.contextual_embedding = ContextualEmbeddingLayer(2*emb_dim, 2*emb_dim)\n","\n","        self.dropout = nn.Dropout()\n","        self.similarity_weight = nn.Linear(6*(2*emb_dim), 1, bias=False)\n","        self.modeling_trans = nn.TransformerEncoderLayer(8*(2*emb_dim), batch_first=True, nhead=8)\n","        self.linear1 = nn.Sequential(nn.Linear(8*(2*emb_dim), 2*2*emb_dim), nn.ReLU())\n","        self.output_start = nn.Linear(10*(2*emb_dim), 1, bias=False)\n","        self.output_end = nn.Linear(10*(2*emb_dim), 1, bias=False)\n","        self.end_trans = nn.TransformerEncoderLayer(2*emb_dim*2, batch_first=True, nhead=8)\n","        self.linear2 = nn.Sequential(nn.Linear(2*emb_dim*2, 2*2*emb_dim), nn.ReLU())\n","\n","    def get_glove_embedding(self):\n","        \n","        weights_matrix = np.load('bidafglove100.npy')\n","        num_embeddings, embedding_dim = weights_matrix.shape\n","        embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights_matrix).to(self.device),freeze=True)\n","\n","        return embedding\n","\n","    def forward(self, ctx, ques, char_ctx, char_ques):\n","        \n","        ctx_len = ctx.shape[1]\n","        ques_len = ques.shape[1]\n","        \n","        ctx_word_embed = self.word_embedding(ctx)\n","        ctx_char_embed = self.character_embedding(char_ctx)\n","        # print(\"che\")\n","        ctx_contextual_in = torch.cat([ctx_word_embed, ctx_char_embed], dim=2)\n","        ctx_contextual_embed = self.contextual_embedding(ctx_contextual_in)\n","        # print(\"coe\")\n","\n","        ques_word_embed = self.word_embedding(ques)\n","        ques_char_embed = self.character_embedding(char_ques)\n","        # print(\"qhe\")\n","        ques_contextual_in = torch.cat([ques_word_embed, ques_char_embed], dim=2)\n","        ques_contextual_embed = self.contextual_embedding(ques_contextual_in)\n","        # print(\"qoe\")\n","        # Similarity Matrix\n","        c = ctx_contextual_embed.unsqueeze(2).repeat(1, 1, ques_len, 1)\n","        q = ques_contextual_embed.unsqueeze(1).repeat(1, ctx_len, 1, 1)\n","\n","        elementwise = torch.mul(c, q)\n","        alpha = torch.cat([c, q, elementwise], dim=3)\n","        similarity_matrix = self.similarity_weight(alpha).view(-1, ctx_len, ques_len)\n","\n","        # Context2Query Attention\n","        a = F.softmax(similarity_matrix, dim=-1)\n","        c2q = torch.bmm(a, ques_contextual_embed)\n","\n","        # Query2Context Attention\n","        b = F.softmax(torch.max(similarity_matrix, 2)[0], dim=-1)\n","        b = b.unsqueeze(1)\n","        q2c = torch.bmm(b, ctx_contextual_embed)\n","        q2c = q2c.repeat(1, ctx_len, 1)\n","\n","        # Query Aware Representation\n","        G = torch.cat([ctx_contextual_embed, c2q, torch.mul(ctx_contextual_embed, c2q), torch.mul(ctx_contextual_embed, q2c)], dim=2)\n","\n","        # Modeling Layer\n","        M = self.modeling_trans(G)\n","        M = self.linear1(M)\n","\n","        # Output Layer\n","        M2 = self.end_trans(M)\n","        self.linear2(M)\n","\n","        p1 = self.output_start(torch.cat([G, M], dim=2)).squeeze()\n","\n","        p2 = self.output_start(torch.cat([G, M2], dim=2)).squeeze()\n","\n","        return p1, p2\n","\n","\n","\n"],"metadata":{"id":"LqhRj1YNPiG3","executionInfo":{"status":"ok","timestamp":1668617959445,"user_tz":-330,"elapsed":731,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["#Training"],"metadata":{"id":"nfiYAjDSqX9a"}},{"cell_type":"code","source":["CHAR_VOCAB_DIM = len(char2idx)\n","EMB_DIM = 100\n","CHAR_EMB_DIM = 8\n","NUM_OUTPUT_CHANNELS = 100\n","KERNEL_SIZE = (8,5)\n","HIDDEN_DIM = 300\n","device = torch.device('cuda:0')\n","device = torch.device('cpu')\n","\n","model = BiDAF(CHAR_VOCAB_DIM, \n","              EMB_DIM, \n","              CHAR_EMB_DIM, \n","              NUM_OUTPUT_CHANNELS, \n","              KERNEL_SIZE, \n","              device).to(device)\n"],"metadata":{"id":"LB9tPYM7hui0","executionInfo":{"status":"ok","timestamp":1668617959446,"user_tz":-330,"elapsed":2,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm"],"metadata":{"id":"xzYBBF5Ss0Z6","executionInfo":{"status":"ok","timestamp":1668617960257,"user_tz":-330,"elapsed":6,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","from torch.autograd import Variable\n","optimizer = optim.Adadelta(model.parameters())"],"metadata":{"id":"x_QhogYgqsea","executionInfo":{"status":"ok","timestamp":1668617960257,"user_tz":-330,"elapsed":5,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["def train(model, train_dataset):\n","    print(\"training\")\n","    train_loss = 0.\n","    batch_count = 0\n","    model.train()\n","\n","    for batch in tqdm(train_dataset):\n","        optimizer.zero_grad()\n","\n","        if batch_count%500 == 0:\n","            print(f\"Starting batch: {batch_count}\")\n","\n","        batch_count += 1\n","\n","        context, question, char_ctx, char_ques, label, ctx_text, ans, ids = batch\n","        context, question, char_ctx, char_ques, label = context.to(device), question.to(device), char_ctx.to(device), char_ques.to(device), label.to(device)\n","\n","        preds = model(context, question, char_ctx, char_ques)\n","\n","        start_pred, end_pred = preds\n","        s_idx, e_idx = label[:,0], label[:,1]\n","\n","        loss = F.cross_entropy(start_pred, s_idx) + F.cross_entropy(end_pred, e_idx)\n","        loss.backward()\n","\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    return train_loss/len(train_dataset)\n"],"metadata":{"id":"VpJq7ByurLak","executionInfo":{"status":"ok","timestamp":1668617960257,"user_tz":-330,"elapsed":5,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["def valid(model, valid_dataset):\n","    print(\"Validating....\")\n","    valid_loss = 0.\n","    batch_count = 0\n","    f1, em = 0., 0.\n","    model.eval()\n","    predictions = {}\n","\n","    for batch in valid_dataset:\n","        if batch_count % 500 == 0:\n","            print(f\"Starting batch {batch_count}\")\n","        batch_count += 1\n","\n","        context, question, char_ctx, char_ques, label, ctx, answers, ids = batch\n","        context, question, char_ctx, char_ques, label = context.to(device), question.to(device), char_ctx.to(device), char_ques.to(device), label.to(device)\n","\n","        with torch.no_grad():\n","            s_idx, e_idx = label[:, 0], label[:, 0]\n","            preds = model(context, question, char_ctx, char_ques)\n","\n","            p1, p2 = preds\n","            loss = F.cross_entropy(p1, s_idx) + F.cross_entropy(p2, e_idx)\n","            valid_loss += loss.item()\n","\n","            batch_size, c_len = p1.size()\n","            ls = nn.LogSoftmax(dim=1)\n","            mask = (torch.ones(c_len, c_len) * float('-inf')).to(device).tril(-1).unsqueeze(0).expand(batch_size, -1, -1)\n","            score = (ls(p1).unsqueeze(2) + ls(p2).unsqueeze(1)) + mask\n","            score, s_idx = score.max(dim=1)\n","            score, e_idx = score.max(dim=1)\n","            s_idx = torch.gather(s_idx, 1, e_idx.view(-1, 1)).squeeze()\n","            \n","           \n","            for i in range(batch_size):\n","                id = ids[i]\n","                pred = context[i][s_idx[i]:e_idx[i]+1]\n","                pred = ' '.join([idx2word[idx.item()] for idx in pred])\n","                predictions[id] = pred   \n","\n","    \n","    em, f1 = evaluate(predictions)\n","    print(\"done\")\n","    return valid_loss/len(valid_dataset), em, f1\n"],"metadata":{"id":"-H-6inS-uPBf","executionInfo":{"status":"ok","timestamp":1668617960257,"user_tz":-330,"elapsed":4,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["def normalize_answer(s):\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","\n","def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n","    scores_for_ground_truths = []\n","    for ground_truth in ground_truths:\n","        score = metric_fn(prediction, ground_truth)\n","        scores_for_ground_truths.append(score)\n","        \n","    return max(scores_for_ground_truths)\n","\n","\n","def f1_score(prediction, ground_truth):\n","    prediction_tokens = normalize_answer(prediction).split()\n","    ground_truth_tokens = normalize_answer(ground_truth).split()\n","    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n","    num_same = sum(common.values())\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(prediction_tokens)\n","    recall = 1.0 * num_same / len(ground_truth_tokens)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1\n","\n","\n","def exact_match_score(prediction, ground_truth):\n","    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n","\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"F_C8ixn4l6sT","executionInfo":{"status":"ok","timestamp":1668617960257,"user_tz":-330,"elapsed":4,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["def evaluate(predictions):\n","\n","    with open(\"../data/squad_dev.json\", \"r\", encoding=\"utf-8\") as f:\n","        dataset = json.load(f)\n","\n","    dataset = dataset[\"data\"]\n","    f1 = exact_match = total = 0\n","    for article in dataset:\n","        for paragraphs in article[\"paragraphs\"]:\n","            for qa in paragraphs[\"qas\"]:\n","                total+=1\n","                if qa[\"id\"] not in predictions:\n","                    continue\n","                \n","                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n","                prediction = predictions[qa['id']]\n","                \n","                exact_match += metric_max_over_ground_truths(\n","                    exact_match_score, prediction, ground_truths)\n","                \n","                f1 += metric_max_over_ground_truths(\n","                    f1_score, prediction, ground_truths)\n","                \n","    \n","    exact_match = 100.0 * exact_match / total\n","    f1 = 100.0 * f1 / total\n","    \n","    return exact_match, f1"],"metadata":{"id":"svp-gqsMkpX2","executionInfo":{"status":"ok","timestamp":1668618044961,"user_tz":-330,"elapsed":760,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["train_losses = []\n","valid_losses = []\n","ems = []\n","f1s = []\n","epochs = 5\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}\")\n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_dataset)\n","    valid_loss, em, f1 = valid(model, valid_dataset)\n","    \n","    torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': valid_loss,\n","            'em':em,\n","            'f1':f1,\n","            }, 'bidaf_run4_{}.pth'.format(epoch))\n","    \n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    ems.append(em)\n","    f1s.append(f1)\n","\n","    print(f\"Epoch train loss : {train_loss}| Time: {epoch_mins}m {epoch_secs}s\")\n","    print(f\"Epoch valid loss: {valid_loss}\")\n","    print(f\"Epoch EM: {em}\")\n","    print(f\"Epoch F1: {f1}\")\n","    print(\"====================================================================================\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":718},"id":"GRVJHvUCnNFA","outputId":"c2030ba9-7dec-4ff6-ffa8-e04bb8cd587d","executionInfo":{"status":"error","timestamp":1668618101568,"user_tz":-330,"elapsed":56613,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","training\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/7 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7/7 [00:29<00:00,  4.25s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Validating....\n","Starting batch 0\n","done\n","Epoch train loss : 9.745165961129326| Time: 0m 35s\n","Epoch valid loss: 8.648008584976196\n","Epoch EM: 0.0\n","Epoch F1: 0.003784295175023652\n","====================================================================================\n","Epoch 2\n","training\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/7 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 0\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 4/7 [00:21<00:15,  5.30s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-a30ba2250b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-45-545926e46af0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_ques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_ques\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_ques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mstart_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-41-b488a17e1583>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ctx, ques, char_ctx, char_ques)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Modeling Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_trans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Output Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"z-6J0ddnaa6Q"},"execution_count":null,"outputs":[]}]}