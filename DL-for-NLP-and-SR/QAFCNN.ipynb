{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPaTT5hATyqvjPeFTBpNdgE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGXzBPwm9V59","executionInfo":{"status":"ok","timestamp":1668568089772,"user_tz":-330,"elapsed":3877,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"94565914-e436-4cdf-dae6-c416b53b32fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd drive/MyDrive/Project/squad/qafcnn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_K5PSlF-mGK","executionInfo":{"status":"ok","timestamp":1668568089772,"user_tz":-330,"elapsed":10,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"d16dbc6f-10d7-43f9-e555-2f09c69ffba0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project/squad/qafcnn\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import re, os, string, typing, gc, json\n","import spacy\n","from collections import Counter\n","\n","from torch import nn\n","import torch\n","import numpy as np\n","import pandas as pd\n","import pickle, time\n","import re, os, string, typing, gc, json\n","import torch.nn.functional as F\n","import spacy\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","nlp = spacy.blank('en')\n","\n","# import sys\n","# sys.path.insert(1, '%cd /drive/MyDrive/Project/squad')\n","from drive.MyDrive.Project.squad.preprocess import *"],"metadata":{"id":"4_59lIZ0-tqB","executionInfo":{"status":"error","timestamp":1668577804373,"user_tz":-330,"elapsed":17340,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"colab":{"base_uri":"https://localhost:8080/","height":334},"outputId":"de9f815d-1391-4ed0-bd78-feba9bea9e24"},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-da584e89a974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# import sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# sys.path.insert(1, '%cd /drive/MyDrive/Project/squad')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMyDrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'drive'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["#Data Loader"],"metadata":{"id":"b3JHmTQXAlW5"}},{"cell_type":"code","source":["with open('../QANET/qanetw2id.pickle','rb') as handle:\n","    word2idx = pickle.load(handle)\n","with open('../QANET/qanetc2id.pickle','rb') as handle:\n","    char2idx = pickle.load(handle)"],"metadata":{"id":"gYo48dfc-w0S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_pickle('../QANET/qanettrain.pkl')\n","valid_df = pd.read_pickle('../QANET/qanetvalid.pkl')"],"metadata":{"id":"utPp0e7NBEUU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idx2word = {v:k for k,v in word2idx.items()}"],"metadata":{"id":"7ePuR5hDBSzC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SQuAD:\n","    def __init__(self, data, batch_size):\n","        self.batch_size = batch_size\n","        data = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\n","        self.data = data\n","        \n","        \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def make_char_vector(self, max_sent_len, sentence, max_word_len=16):\n","        \n","        char_vec = torch.zeros(max_sent_len, max_word_len).type(torch.LongTensor)\n","        \n","        for i, word in enumerate(nlp(sentence, disable=['parser','tagger','ner'])):\n","            for j, ch in enumerate(word.text):\n","                if j == max_word_len:\n","                    break\n","                char_vec[i][j] = char2idx.get(ch, 0)\n","        \n","        return char_vec     \n","    \n","    def get_span(self, text):\n","\n","        text = nlp(text, disable=['parser','tagger','ner'])\n","        span = [(w.idx, w.idx+len(w.text)) for w in text]\n","\n","        return span\n","\n","    \n","    def __iter__(self):\n","        \n","        for batch in self.data:\n","            \n","            spans = []\n","            ctx_text = []\n","            answer_text = []\n","            \n","             \n","            for ctx in batch.context:\n","                ctx_text.append(ctx)\n","                spans.append(self.get_span(ctx))\n","            \n","            for ans in batch.answer:\n","                answer_text.append(ans)\n","                \n","            max_context_len = max([len(ctx) for ctx in batch.context_ids])\n","            padded_context = torch.LongTensor(len(batch), max_context_len).fill_(1)\n","            \n","            for i, ctx in enumerate(batch.context_ids):\n","                padded_context[i, :len(ctx)] = torch.LongTensor(ctx)\n","                \n","            max_word_ctx = 16\n","          \n","            char_ctx = torch.zeros(len(batch), max_context_len, max_word_ctx).type(torch.LongTensor)\n","            for i, context in enumerate(batch.context):\n","                char_ctx[i] = self.make_char_vector(max_context_len, context)\n","            \n","            max_question_len = max([len(ques) for ques in batch.question_ids])\n","            padded_question = torch.LongTensor(len(batch), max_question_len).fill_(1)\n","            \n","            for i, ques in enumerate(batch.question_ids):\n","                padded_question[i, :len(ques)] = torch.LongTensor(ques)\n","                \n","            max_word_ques = 16\n","            \n","            char_ques = torch.zeros(len(batch), max_question_len, max_word_ques).type(torch.LongTensor)\n","            for i, question in enumerate(batch.question):\n","                char_ques[i] = self.make_char_vector(max_question_len, question)\n","            \n","              \n","            label = torch.LongTensor(list(batch.label_idx))\n","            ids = list(batch.id)\n","            \n","            yield (padded_context, padded_question, char_ctx, char_ques, label, ctx_text, answer_text, ids)\n","            \n","         "],"metadata":{"id":"s4w2p62sBWsN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = SQuAD(train_df, 16)\n","valid_dataset = SQuAD(valid_df, 16)     "],"metadata":{"id":"hi40fzB0BbW9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#FCNN"],"metadata":{"id":"Khwtp1cQN3Vt"}},{"cell_type":"code","source":["class FCNN(nn.Module):\n","    def __init__(self, emb_dim, device):\n","    \n","        super(FCNN, self).__init__()\n","        self.device = device\n","\n","        self.word_embedding = self.get_glove_embedding()\n","\n","        self.dropout = nn.Dropout()\n","        self.similarity_weight = nn.Linear(3*(emb_dim), 1, bias=False)\n","        self.l1 = nn.Linear(4*emb_dim, emb_dim)\n","        self.l2 = nn.Linear(emb_dim, emb_dim)\n","        self.l3 = nn.Linear(emb_dim, emb_dim)\n","        self.output_start = nn.Linear(5*(emb_dim), 1, bias=False)\n","        self.output_end = nn.Linear(5*(emb_dim), 1, bias=False)\n","\n","    def get_glove_embedding(self):\n","        \n","        weights_matrix = np.load('../qanet/qanetglove.npy')\n","        num_embeddings, embedding_dim = weights_matrix.shape\n","        embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights_matrix).to(self.device),freeze=True)\n","\n","        return embedding\n","\n","    def forward(self, ctx, ques, char_ctx, char_ques):\n","        \n","        ctx_len = ctx.shape[1]\n","        ques_len = ques.shape[1]\n","        \n","        ctx_word_embed = self.word_embedding(ctx)\n","\n","        ques_word_embed = self.word_embedding(ques)\n","\n","        # Similarity Matrix\n","        c = ctx_word_embed.unsqueeze(2).repeat(1, 1, ques_len, 1)\n","        q = ques_word_embed.unsqueeze(1).repeat(1, ctx_len, 1, 1)\n","\n","        elementwise = torch.mul(c, q)\n","        alpha = torch.cat([c, q, elementwise], dim=3)\n","        similarity_matrix = self.similarity_weight(alpha).view(-1, ctx_len, ques_len)\n","\n","        # Context2Query Attention\n","        a = F.softmax(similarity_matrix, dim=-1)\n","        c2q = torch.bmm(a, ques_word_embed)\n","\n","        # Query2Context Attention\n","        b = F.softmax(torch.max(similarity_matrix, 2)[0], dim=-1)\n","        b = b.unsqueeze(1)\n","        q2c = torch.bmm(b, ctx_word_embed)\n","        q2c = q2c.repeat(1, ctx_len, 1)\n","\n","        # Query Aware Representation\n","        G = torch.cat([ctx_word_embed, c2q, torch.mul(ctx_word_embed, c2q), torch.mul(ctx_word_embed, q2c)], dim=2)\n","        \n","        M = F.relu(self.l2(F.relu(self.l1(G))))\n","        M2 = F.relu(self.l3(M))\n","\n","        p1 = F.softmax(self.output_start(torch.cat([G, M], dim=2)).squeeze(), dim=-1)\n","\n","        p2 = F.softmax(self.output_start(torch.cat([G, M2], dim=2)).squeeze(), dim=-1)\n","\n","        return p1, p2\n","\n","\n","\n"],"metadata":{"id":"mpOBS6igBdiX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EMB_DIM = 300\n","device = torch.device('cuda:0')\n","\n","model = FCNN(EMB_DIM, device).to(device)"],"metadata":{"id":"W1z7Eo4PMG-a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","from torch.autograd import Variable\n","optimizer = optim.Adadelta(model.parameters())\n","\n","from tqdm import tqdm"],"metadata":{"id":"MUyEz2TpO98Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, train_dataset):\n","    print(\"training\")\n","    train_loss = 0.\n","    batch_count = 0\n","    model.train()\n","\n","    for batch in tqdm(train_dataset):\n","        optimizer.zero_grad()\n","\n","        if batch_count%500 == 0:\n","            print(f\"Starting batch: {batch_count}\")\n","\n","        batch_count += 1\n","\n","        context, question, char_ctx, char_ques, label, ctx_text, ans, ids = batch\n","        context, question, char_ctx, char_ques, label = context.to(device), question.to(device), char_ctx.to(device), char_ques.to(device), label.to(device)\n","\n","        preds = model(context, question, char_ctx, char_ques)\n","\n","        start_pred, end_pred = preds\n","        s_idx, e_idx = label[:,0], label[:,1]\n","\n","        loss = F.cross_entropy(start_pred, s_idx) + F.cross_entropy(end_pred, e_idx)\n","        loss.backward()\n","\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    return train_loss/len(train_dataset)"],"metadata":{"id":"bGPSzdZtWI1P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def valid(model, valid_dataset):\n","    print(\"Validating....\")\n","    valid_loss = 0.\n","    batch_count = 0\n","    f1, em = 0., 0.\n","    model.eval()\n","    predictions = {}\n","\n","    for batch in valid_dataset:\n","        if batch_count % 500 == 0:\n","            print(f\"Starting batch {batch_count}\")\n","        batch_count += 1\n","\n","        context, question, char_ctx, char_ques, label, ctx, answers, ids = batch\n","        context, question, char_ctx, char_ques, label = context.to(device), question.to(device), char_ctx.to(device), char_ques.to(device), label.to(device)\n","\n","        with torch.no_grad():\n","            s_idx, e_idx = label[:, 0], label[:, 0]\n","            preds = model(context, question, char_ctx, char_ques)\n","\n","            p1, p2 = preds\n","            loss = F.cross_entropy(p1, s_idx) + F.cross_entropy(p2, e_idx)\n","            valid_loss += loss.item()\n","\n","            batch_size, c_len = p1.size()\n","            ls = nn.LogSoftmax(dim=1)\n","            mask = (torch.ones(c_len, c_len) * float('-inf')).to(device).tril(-1).unsqueeze(0).expand(batch_size, -1, -1)\n","            score = (ls(p1).unsqueeze(2) + ls(p2).unsqueeze(1)) + mask\n","            score, s_idx = score.max(dim=1)\n","            score, e_idx = score.max(dim=1)\n","            s_idx = torch.gather(s_idx, 1, e_idx.view(-1, 1)).squeeze()\n","            \n","           \n","            for i in range(batch_size):\n","                id = ids[i]\n","                pred = context[i][s_idx[i]:e_idx[i]+1]\n","                pred = ' '.join([idx2word[idx.item()] for idx in pred])\n","                predictions[id] = pred   \n","\n","    \n","    em, f1 = evaluate(predictions)\n","    print(\"done\")\n","    return valid_loss/len(valid_dataset), em, f1"],"metadata":{"id":"_KkmrCTnWIye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalize_answer(s):\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","\n","def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n","    scores_for_ground_truths = []\n","    for ground_truth in ground_truths:\n","        score = metric_fn(prediction, ground_truth)\n","        scores_for_ground_truths.append(score)\n","        \n","    return max(scores_for_ground_truths)\n","\n","\n","def f1_score(prediction, ground_truth):\n","    prediction_tokens = normalize_answer(prediction).split()\n","    ground_truth_tokens = normalize_answer(ground_truth).split()\n","    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n","    num_same = sum(common.values())\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(prediction_tokens)\n","    recall = 1.0 * num_same / len(ground_truth_tokens)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1\n","\n","\n","def exact_match_score(prediction, ground_truth):\n","    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n","\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"yJiVVEr1WQT3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(predictions):\n","\n","    with open(\"../data/squad_dev.json\", \"r\", encoding=\"utf-8\") as f:\n","        dataset = json.load(f)\n","\n","    dataset = dataset[\"data\"]\n","    f1 = exact_match = total = 0\n","    for article in dataset:\n","        for paragraphs in article[\"paragraphs\"]:\n","            for qa in paragraphs[\"qas\"]:\n","                total+=1\n","                if qa[\"id\"] not in predictions:\n","                    continue\n","                \n","                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n","                prediction = predictions[qa['id']]\n","                \n","                exact_match += metric_max_over_ground_truths(\n","                    exact_match_score, prediction, ground_truths)\n","                \n","                f1 += metric_max_over_ground_truths(\n","                    f1_score, prediction, ground_truths)\n","                \n","    \n","    exact_match = 100.0 * exact_match / total\n","    f1 = 100.0 * f1 / total\n","    \n","    return exact_match, f1"],"metadata":{"id":"QKHNUYk4WQRT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_losses = []\n","valid_losses = []\n","ems = []\n","f1s = []\n","epochs = 5\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}\")\n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_dataset)\n","    valid_loss, em, f1 = valid(model, valid_dataset)\n","    \n","    torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': valid_loss,\n","            'em':em,\n","            'f1':f1,\n","            }, 'bidaf_run4_{}.pth'.format(epoch))\n","    \n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    ems.append(em)\n","    f1s.append(f1)\n","\n","    print(f\"Epoch train loss : {train_loss}| Time: {epoch_mins}m {epoch_secs}s\")\n","    print(f\"Epoch valid loss: {valid_loss}\")\n","    print(f\"Epoch EM: {em}\")\n","    print(f\"Epoch F1: {f1}\")\n","    print(\"---------------Done---------------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAY1bGvXWQOO","executionInfo":{"status":"ok","timestamp":1668571763739,"user_tz":-330,"elapsed":3002011,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"fd6faf11-cc9e-4e2b-b84e-94498887d744"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","training\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/5397 [00:00<15:19,  5.87it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 0\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▉         | 501/5397 [00:39<04:51, 16.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 500\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▊        | 1003/5397 [01:13<04:32, 16.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 1000\n"]},{"output_type":"stream","name":"stderr","text":[" 28%|██▊       | 1501/5397 [01:46<03:58, 16.31it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 1500\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 2003/5397 [02:28<04:14, 13.31it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 2000\n"]},{"output_type":"stream","name":"stderr","text":[" 46%|████▋     | 2503/5397 [03:10<03:53, 12.38it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 2500\n"]},{"output_type":"stream","name":"stderr","text":[" 56%|█████▌    | 3002/5397 [03:52<03:47, 10.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 3000\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▍   | 3502/5397 [04:34<03:17,  9.61it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 3500\n"]},{"output_type":"stream","name":"stderr","text":[" 74%|███████▍  | 4002/5397 [05:15<02:00, 11.61it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 4000\n"]},{"output_type":"stream","name":"stderr","text":[" 83%|████████▎ | 4502/5397 [05:58<01:16, 11.74it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 4500\n"]},{"output_type":"stream","name":"stderr","text":[" 93%|█████████▎| 5003/5397 [06:39<00:28, 13.97it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5397/5397 [07:12<00:00, 12.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating....\n","Starting batch 0\n","Starting batch 500\n","Starting batch 1000\n","Starting batch 1500\n","Starting batch 2000\n","done\n","Epoch train loss : 10.304877542093195| Time: 9m 52s\n","Epoch valid loss: 9.932044783220604\n","Epoch EM: 7.729422894985809\n","Epoch F1: 12.983051456152799\n","====================================================================================\n","Epoch 2\n","training\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 2/5397 [00:00<08:15, 10.89it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 0\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▉         | 501/5397 [00:39<07:08, 11.42it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 500\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▊        | 1003/5397 [01:13<04:31, 16.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 1000\n"]},{"output_type":"stream","name":"stderr","text":[" 28%|██▊       | 1502/5397 [01:46<03:41, 17.60it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 1500\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 2002/5397 [02:27<03:59, 14.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 2000\n"]},{"output_type":"stream","name":"stderr","text":[" 46%|████▋     | 2503/5397 [03:11<03:51, 12.52it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 2500\n"]},{"output_type":"stream","name":"stderr","text":[" 56%|█████▌    | 3001/5397 [03:52<03:38, 10.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 3000\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▍   | 3502/5397 [04:34<02:20, 13.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 3500\n"]},{"output_type":"stream","name":"stderr","text":[" 74%|███████▍  | 4002/5397 [05:14<01:57, 11.83it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 4000\n"]},{"output_type":"stream","name":"stderr","text":[" 83%|████████▎ | 4501/5397 [05:58<01:14, 12.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 4500\n"]},{"output_type":"stream","name":"stderr","text":[" 93%|█████████▎| 5002/5397 [06:41<00:27, 14.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5397/5397 [07:13<00:00, 12.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating....\n","Starting batch 0\n","Starting batch 500\n","Starting batch 1000\n","Starting batch 1500\n","Starting batch 2000\n","done\n","Epoch train loss : 10.224057499117071| Time: 9m 55s\n","Epoch valid loss: 9.910852672460493\n","Epoch EM: 8.732261116367077\n","Epoch F1: 14.89093346190782\n","====================================================================================\n","Epoch 3\n","training\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/5397 [00:00<10:13,  8.80it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 0\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▉         | 501/5397 [00:40<04:56, 16.49it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 500\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▊        | 1004/5397 [01:14<04:32, 16.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 1000\n"]},{"output_type":"stream","name":"stderr","text":[" 28%|██▊       | 1502/5397 [01:49<03:46, 17.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 1500\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 2003/5397 [02:30<04:09, 13.61it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 2000\n"]},{"output_type":"stream","name":"stderr","text":[" 46%|████▋     | 2503/5397 [03:15<04:02, 11.93it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 2500\n"]},{"output_type":"stream","name":"stderr","text":[" 56%|█████▌    | 3001/5397 [03:58<03:29, 11.46it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 3000\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▍   | 3502/5397 [04:41<02:23, 13.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 3500\n"]},{"output_type":"stream","name":"stderr","text":[" 74%|███████▍  | 4003/5397 [05:24<01:59, 11.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 4000\n"]},{"output_type":"stream","name":"stderr","text":[" 83%|████████▎ | 4502/5397 [06:06<01:17, 11.49it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 4500\n"]},{"output_type":"stream","name":"stderr","text":[" 93%|█████████▎| 5003/5397 [06:50<00:29, 13.26it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5397/5397 [07:23<00:00, 12.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating....\n","Starting batch 0\n","Starting batch 500\n","Starting batch 1000\n","Starting batch 1500\n","Starting batch 2000\n","done\n","Epoch train loss : 10.188865631227916| Time: 10m 9s\n","Epoch valid loss: 9.892804049773956\n","Epoch EM: 9.24314096499527\n","Epoch F1: 16.327613237658493\n","====================================================================================\n","Epoch 4\n","training\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/5397 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 0\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▉         | 501/5397 [00:40<05:06, 15.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 500\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▊        | 1004/5397 [01:16<04:35, 15.96it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 1000\n"]},{"output_type":"stream","name":"stderr","text":[" 28%|██▊       | 1501/5397 [01:49<03:59, 16.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 1500\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 2002/5397 [02:32<04:08, 13.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 2000\n"]},{"output_type":"stream","name":"stderr","text":[" 46%|████▋     | 2502/5397 [03:16<04:12, 11.47it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 2500\n"]},{"output_type":"stream","name":"stderr","text":[" 56%|█████▌    | 3001/5397 [03:58<03:28, 11.49it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 3000\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▍   | 3502/5397 [04:41<02:22, 13.33it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 3500\n"]},{"output_type":"stream","name":"stderr","text":[" 74%|███████▍  | 4003/5397 [05:23<01:57, 11.84it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 4000\n"]},{"output_type":"stream","name":"stderr","text":[" 83%|████████▎ | 4502/5397 [06:06<01:17, 11.56it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 4500\n"]},{"output_type":"stream","name":"stderr","text":[" 93%|█████████▎| 5001/5397 [06:49<00:39,  9.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5397/5397 [07:22<00:00, 12.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating....\n","Starting batch 0\n","Starting batch 500\n","Starting batch 1000\n","Starting batch 1500\n","Starting batch 2000\n","done\n","Epoch train loss : 10.159802252967555| Time: 10m 6s\n","Epoch valid loss: 9.882048839246723\n","Epoch EM: 9.943235572374645\n","Epoch F1: 17.631802074602028\n","====================================================================================\n","Epoch 5\n","training\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/5397 [00:00<13:09,  6.83it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 0\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▉         | 501/5397 [00:40<05:06, 15.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 500\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▊        | 1003/5397 [01:15<04:38, 15.78it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 1000\n"]},{"output_type":"stream","name":"stderr","text":[" 28%|██▊       | 1501/5397 [01:50<04:02, 16.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 1500\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 2003/5397 [02:31<04:10, 13.53it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 2000\n"]},{"output_type":"stream","name":"stderr","text":[" 46%|████▋     | 2503/5397 [03:15<03:53, 12.39it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 2500\n"]},{"output_type":"stream","name":"stderr","text":[" 56%|█████▌    | 3001/5397 [03:57<03:25, 11.67it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 3000\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▍   | 3502/5397 [04:38<02:18, 13.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 3500\n"]},{"output_type":"stream","name":"stderr","text":[" 74%|███████▍  | 4002/5397 [05:20<01:56, 11.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 4000\n"]},{"output_type":"stream","name":"stderr","text":[" 83%|████████▎ | 4502/5397 [06:02<01:16, 11.66it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 4500\n"]},{"output_type":"stream","name":"stderr","text":[" 93%|█████████▎| 5002/5397 [06:44<00:28, 13.97it/s]"]},{"output_type":"stream","name":"stdout","text":["Starting batch: 5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5397/5397 [07:16<00:00, 12.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating....\n","Starting batch 0\n","Starting batch 500\n","Starting batch 1000\n","Starting batch 1500\n","Starting batch 2000\n","done\n","Epoch train loss : 10.146143917775008| Time: 9m 58s\n","Epoch valid loss: 9.880302768805777\n","Epoch EM: 9.593188268684957\n","Epoch F1: 16.830685366590135\n","====================================================================================\n"]}]},{"cell_type":"code","source":["!touch main.py"],"metadata":{"id":"83i4BB3yWV_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkQjXtiYWV9l","executionInfo":{"status":"ok","timestamp":1668572927466,"user_tz":-330,"elapsed":8,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"a51dd254-5ca0-4340-a5b2-e6a0aba7a27d"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["bidaf_run4_0.pth  bidaf_run4_2.pth  bidaf_run4_4.pth\n","bidaf_run4_1.pth  bidaf_run4_3.pth  main.py\n"]}]},{"cell_type":"code","source":["%cd ../"],"metadata":{"id":"3NhoCBJcqTCA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668572936343,"user_tz":-330,"elapsed":7,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"3eae544f-498e-4d37-f16c-592ed63c1350"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project/squad\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eiTpD-VMsm6x","executionInfo":{"status":"ok","timestamp":1668572940029,"user_tz":-330,"elapsed":649,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"c0e039ec-f193-4714-9ef3-37c76ac47cc6"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["bidaf\t\t  bidaf_run4_2.pth  data\t main.py\tqafcnn\n","bidaf_run4_0.pth  bidaf_run4_3.pth  evaluate.py  preprocess.py\tqanet\n","bidaf_run4_1.pth  bidaf_run4_4.pth  GloVe\t __pycache__\n"]}]},{"cell_type":"code","source":["%cd bidaf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G-XfM_FbsnzO","executionInfo":{"status":"ok","timestamp":1668572953322,"user_tz":-330,"elapsed":8,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"fd64ed1e-3d9c-4ad8-a4e9-4f6d483935df"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project/squad/bidaf\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzN0Ty4FsrIV","executionInfo":{"status":"ok","timestamp":1668572958252,"user_tz":-330,"elapsed":10,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"defd92e6-8ad1-4bc2-83c8-6328f8180cdd"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["bidafc2id.pickle   bidafglove.npy  bidafvalid.pkl    main2.py\n","bidafglove100.npy  bidaftrain.pkl  bidafw2id.pickle  main.py\n"]}]},{"cell_type":"code","source":["!touch main_rnn.py"],"metadata":{"id":"c-WHgzyktxmV","executionInfo":{"status":"ok","timestamp":1668573287806,"user_tz":-330,"elapsed":7,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhVz2YhAt874","executionInfo":{"status":"ok","timestamp":1668573293236,"user_tz":-330,"elapsed":11,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"f92ef54a-21b0-4751-fd27-2103eadd300c"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["bidafc2id.pickle   bidaftrain.pkl    main2.py\t  preprocess.py\n","bidafglove100.npy  bidafvalid.pkl    main.py\t  __pycache__\n","bidafglove.npy\t   bidafw2id.pickle  main_rnn.py\n"]}]},{"cell_type":"code","source":["!python main_rnn.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NXd3i0-2t-RK","executionInfo":{"status":"ok","timestamp":1668573552916,"user_tz":-330,"elapsed":23295,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"700b1f34-e7a3-4bd2-d184-63b0f2d5f910"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","training\n","  0% 0/10827 [00:00<?, ?it/s]Starting batch: 0\n","  1% 56/10827 [00:07<23:28,  7.65it/s]\n","Traceback (most recent call last):\n","  File \"main_rnn.py\", line 470, in <module>\n","  File \"main_rnn.py\", line 309, in train\n","    for batch in tqdm(train_dataset):\n","  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1195, in __iter__\n","    for obj in iterable:\n","  File \"main_rnn.py\", line 95, in __iter__\n","    char_ctx[i] = self.make_char_vector(max_context_len, max_word_ctx, context)\n","  File \"main_rnn.py\", line 56, in make_char_vector\n","    char_vec[i][j] = char2idx.get(ch, 0)\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["import math"],"metadata":{"id":"SxEpvcXpAb7K","executionInfo":{"status":"ok","timestamp":1668578137158,"user_tz":-330,"elapsed":4,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, hidden_size, dropout=0.1, num_heads=10):\n","        super(MultiHeadAttention, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_heads = num_heads\n","        self.dropout = dropout\n","        self.head_size = int(hidden_size / num_heads)\n","        assert self.head_size * num_heads == self.hidden_size\n","\n","        self.query = nn.Linear(hidden_size, self.hidden_size)\n","        self.key = nn.Linear(hidden_size, self.hidden_size)\n","        self.value = nn.Linear(hidden_size, self.hidden_size)\n","\n","        self.dense = nn.Linear(2*hidden_size, hidden_size)\n","\n","    def transpose_for_scores(self, x):\n","        new_x_shape = x.size()[:-1] + (self.num_heads, self.head_size)\n","        x = x.view(*new_x_shape)\n","        return x.permute(0, 2, 1, 3)\n","\n","    def forward(self, hidden_states, memory, attention_mask):\n","        mixed_query_layer = self.query(hidden_states)\n","        mixed_key_layer = self.key(memory)\n","        mixed_value_layer = self.value(memory)\n","\n","        query_layer = self.transpose_for_scores(mixed_query_layer)\n","        key_layer = self.transpose_for_scores(mixed_key_layer)\n","        value_layer = self.transpose_for_scores(mixed_value_layer)\n","        print(value_layer.size())\n","\n","        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n","        print(attention_scores.size())\n","        attention_scores = attention_scores / torch.sqrt(torch.FloatTensor([self.head_size])).cuda()\n","        print(attention_scores.size())\n","        attention_scores = attention_scores - 1e30 * (1 - attention_mask[:,None,None, :])\n","\n","        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n","        attention_probs = nn.Dropout(self.dropout)(attention_probs)\n","\n","        context_layer = torch.matmul(attention_probs, value_layer)\n","        print(context_layer.size())\n","        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n","        print(context_layer.size())\n","        new_context_layer_shape = context_layer.size()[:-2] + (self.hidden_size,)\n","        context_layer = context_layer.view(*new_context_layer_shape)\n","        print(context_layer.size())\n","\n","        ou = torch.cat([hidden_states, context_layer], dim=-1)\n","\n","        attention_output = self.dense(ou)\n","        return F.relu(attention_output)"],"metadata":{"id":"ARMbZ-Qsu4CP","executionInfo":{"status":"ok","timestamp":1668582360318,"user_tz":-330,"elapsed":7,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":166,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6tXilzZLPqyu","executionInfo":{"status":"ok","timestamp":1668582360318,"user_tz":-330,"elapsed":5,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":166,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda:0')"],"metadata":{"id":"1Em-DsZlGH5K","executionInfo":{"status":"ok","timestamp":1668582360319,"user_tz":-330,"elapsed":5,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":167,"outputs":[]},{"cell_type":"code","source":["mha = MultiHeadAttention(200).to(device)"],"metadata":{"id":"lHSxPkJb_j3g","executionInfo":{"status":"ok","timestamp":1668582360319,"user_tz":-330,"elapsed":5,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":168,"outputs":[]},{"cell_type":"code","source":["msk = (torch.randn((12, 40)) > 0).float().to(device)"],"metadata":{"id":"CeeL6wlRAaol","executionInfo":{"status":"ok","timestamp":1668582361571,"user_tz":-330,"elapsed":7,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}}},"execution_count":169,"outputs":[]},{"cell_type":"code","source":["inp = torch.randn((12, 40, 200)).to(device)\n","inp.size() + "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQtyh0FO_rom","executionInfo":{"status":"ok","timestamp":1668582362860,"user_tz":-330,"elapsed":12,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"f6f8b7a2-0e30-41ca-f7bd-54c6cf067da7"},"execution_count":170,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12, 40, 200])"]},"metadata":{},"execution_count":170}]},{"cell_type":"code","source":["oup = mha(inp, inp, msk)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttq8uIO1APQU","executionInfo":{"status":"ok","timestamp":1668582362860,"user_tz":-330,"elapsed":9,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"36f879b0-1ae7-4637-e01e-926d92a28fac"},"execution_count":171,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([12, 10, 40, 20])\n","torch.Size([12, 10, 40, 40])\n","torch.Size([12, 10, 40, 40])\n","torch.Size([12, 10, 40, 20])\n","torch.Size([12, 40, 10, 20])\n","torch.Size([12, 40, 200])\n"]}]},{"cell_type":"code","source":["oup.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XWYUmUhTN8ss","executionInfo":{"status":"ok","timestamp":1668582367507,"user_tz":-330,"elapsed":6,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"ecbdc2fa-23b5-4e6d-b817-1d864e7e049d"},"execution_count":172,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12, 40, 200])"]},"metadata":{},"execution_count":172}]},{"cell_type":"code","source":["jk = torch.randn([12, 10, 40, 20])\n","jk.size()[:-2] + (800,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-g0PuDSaK6Wf","executionInfo":{"status":"ok","timestamp":1668582586173,"user_tz":-330,"elapsed":584,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"ea7ce604-1c3c-4f1f-f61a-db2b80de469f"},"execution_count":174,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12, 10, 800])"]},"metadata":{},"execution_count":174}]},{"cell_type":"code","source":["jk - msk[:, None]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxeD2OgwMJTB","executionInfo":{"status":"ok","timestamp":1668581211523,"user_tz":-330,"elapsed":5,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"4f9b3050-3bc0-47ad-b084-7c0720ebd7d9"},"execution_count":132,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.0126, -2.1837, -0.5596,  ..., -0.0681, -0.9773,  0.3364],\n","         [ 0.8043, -3.4792,  0.7756,  ..., -1.5371, -0.3824, -1.8916],\n","         [-0.7206, -1.7320,  0.4998,  ...,  0.2066,  0.0157, -0.0585],\n","         ...,\n","         [-0.2690, -0.3023, -2.0801,  ..., -1.4509,  0.6430, -1.8389],\n","         [-0.7647,  1.5724,  0.7006,  ..., -1.2573,  0.4690, -3.2597],\n","         [-1.5683, -2.3968,  0.2595,  ..., -1.3187,  0.8512, -0.8413]],\n","\n","        [[-1.0174, -2.5141, -0.7108,  ..., -1.4397,  0.5852, -1.8142],\n","         [-0.9676,  0.6741, -0.7844,  ...,  0.1234, -1.2307,  0.2743],\n","         [ 0.4299,  0.9110,  0.1502,  ..., -1.3556,  2.0762, -1.6457],\n","         ...,\n","         [-1.7616, -1.2087, -1.0000,  ..., -1.6305, -1.1972, -1.2158],\n","         [-2.7566,  0.1825, -0.1549,  ..., -2.1681, -0.5929,  0.5348],\n","         [-0.5984, -1.2707, -0.4227,  ..., -2.2108,  0.0104,  1.1768]],\n","\n","        [[-0.5635, -0.7812, -1.7948,  ..., -3.0906,  1.6500, -0.1906],\n","         [ 1.8300, -0.3608, -1.7437,  ..., -2.6945,  0.8621, -0.1446],\n","         [-0.8238, -2.1656, -1.4160,  ...,  1.7338, -1.9679, -1.1889],\n","         ...,\n","         [-0.3916, -0.9523, -0.1523,  ..., -0.9561, -1.0658, -1.5446],\n","         [ 2.2797,  0.7283, -0.8116,  ..., -0.8705,  0.7550, -0.9799],\n","         [-0.2432, -1.1031, -2.3014,  ..., -1.8256,  0.1968, -0.9493]],\n","\n","        ...,\n","\n","        [[-1.4431,  0.4757,  0.7985,  ...,  0.3716,  0.1637, -1.1614],\n","         [-1.8207, -0.3787,  0.2879,  ...,  0.1630, -0.7480, -0.3148],\n","         [-2.7718,  1.4340, -2.3241,  ..., -0.4954, -0.7725,  0.1239],\n","         ...,\n","         [-0.7898, -0.5244, -0.4153,  ..., -0.7333, -1.1889, -0.1329],\n","         [-3.4482,  0.1719,  0.6781,  ..., -0.8126, -1.9822, -1.4363],\n","         [-1.8156,  0.1417, -0.4855,  ...,  1.4963, -0.7378, -0.0688]],\n","\n","        [[-1.3112, -0.9350, -0.1970,  ...,  0.0892, -1.9853,  0.5951],\n","         [ 0.3518, -0.0140, -1.2789,  ...,  0.9611, -0.8146, -0.2389],\n","         [-0.1882, -1.8310, -0.2436,  ...,  0.8343, -1.3798, -1.6944],\n","         ...,\n","         [-0.1916, -0.2078,  0.3068,  ..., -0.4327,  0.2235, -0.8408],\n","         [-0.6463, -1.8849, -0.8600,  ...,  0.2162, -0.5003, -0.8830],\n","         [ 0.5331,  1.3765, -2.3467,  ...,  0.1853, -1.7845,  0.1353]],\n","\n","        [[-1.0441, -0.5294, -0.9902,  ..., -0.6331,  0.6965, -1.3259],\n","         [ 0.0877, -0.3972,  0.4190,  ...,  1.2054, -0.0998, -0.6786],\n","         [ 1.8526, -0.5405, -0.9245,  ...,  1.2602,  1.3119, -1.6879],\n","         ...,\n","         [ 2.2152,  0.0316,  1.0326,  ..., -0.7071, -0.1603,  0.5627],\n","         [ 1.0571, -1.1989,  0.2568,  ...,  1.3570, -0.2593,  0.5208],\n","         [-0.7605, -0.6313,  0.4228,  ..., -2.2163,  0.6632, -1.6524]]])"]},"metadata":{},"execution_count":132}]},{"cell_type":"code","source":["msk = (torch.randn(12, 40) > 0).float()\n","msk[:, None], msk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GiDrBwzVH0Vd","executionInfo":{"status":"ok","timestamp":1668581106780,"user_tz":-330,"elapsed":488,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"25367c3b-d950-4164-d16a-abe34375cbf0"},"execution_count":130,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n","           1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n","           1., 1., 1., 1., 0., 1.]],\n"," \n","         [[1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0.,\n","           1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n","           0., 0., 0., 1., 1., 0.]],\n"," \n","         [[0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n","           0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.,\n","           1., 1., 0., 1., 0., 1.]],\n"," \n","         [[1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n","           1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,\n","           1., 1., 0., 0., 0., 1.]],\n"," \n","         [[0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n","           1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n","           0., 1., 1., 1., 1., 0.]],\n"," \n","         [[0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n","           1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n","           1., 1., 0., 1., 1., 0.]],\n"," \n","         [[1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n","           0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n","           0., 1., 0., 1., 1., 1.]],\n"," \n","         [[1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n","           0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n","           1., 1., 1., 0., 0., 1.]],\n"," \n","         [[1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n","           1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n","           0., 1., 0., 0., 1., 0.]],\n"," \n","         [[1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n","           1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n","           1., 1., 1., 0., 1., 0.]],\n"," \n","         [[0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n","           1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n","           1., 1., 0., 0., 1., 0.]],\n"," \n","         [[0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n","           0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n","           0., 0., 0., 0., 0., 1.]]]),\n"," tensor([[0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n","          0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n","          1., 1., 0., 1.],\n","         [1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n","          1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","          0., 1., 1., 0.],\n","         [0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n","          1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n","          0., 1., 0., 1.],\n","         [1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n","          1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n","          0., 0., 0., 1.],\n","         [0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n","          1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n","          1., 1., 1., 0.],\n","         [0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n","          1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n","          0., 1., 1., 0.],\n","         [1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n","          0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n","          0., 1., 1., 1.],\n","         [1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n","          0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n","          1., 0., 0., 1.],\n","         [1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n","          1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n","          0., 0., 1., 0.],\n","         [1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1.,\n","          1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n","          1., 0., 1., 0.],\n","         [0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n","          0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n","          0., 0., 1., 0.],\n","         [0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n","          1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n","          0., 0., 0., 1.]]))"]},"metadata":{},"execution_count":130}]},{"cell_type":"code","source":[],"metadata":{"id":"s4_-iCLFJu1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.eq(torch.tensor([[1, 2], [3, 4]]), 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdzKWm2fI_0o","executionInfo":{"status":"ok","timestamp":1668580424457,"user_tz":-330,"elapsed":5,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"463d8a68-3836-4a2e-ca9d-dae04baef43b"},"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ True, False],\n","        [False, False]])"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":[],"metadata":{"id":"awLg8BEgJBuI"},"execution_count":null,"outputs":[]}]}