{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxtQe5TIQI4DyejWLlGrCJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#Move to folder"],"metadata":{"id":"O5HLcEwfRVD7"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ev8N9OPaRfAF","executionInfo":{"status":"ok","timestamp":1668652045798,"user_tz":-330,"elapsed":27966,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"a2860366-4fa4-4c43-d5ff-abb39b3d9ed0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9be7r1rBRSri","executionInfo":{"status":"ok","timestamp":1668652046458,"user_tz":-330,"elapsed":666,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"e95b678e-bee5-469c-ee95-116f34f1cf42"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project/squad/qanet\n"]}],"source":["%cd drive/MyDrive/Project/squad/qanet"]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import re, os, string, typing, gc, json\n","import spacy\n","from collections import Counter\n","\n","from torch import nn\n","import torch\n","import numpy as np\n","import pandas as pd\n","import pickle, time\n","import re, os, string, typing, gc, json\n","import torch.nn.functional as F\n","import spacy\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","from tqdm import tqdm\n","nlp = spacy.blank('en')\n","\n","# import sys\n","# sys.path.insert(1, '%cd /drive/MyDrive/Project/squad')\n","from drive.MyDrive.Project.squad.preprocess import *"],"metadata":{"id":"EXWqKopLRs7o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Preprocess Data"],"metadata":{"id":"Tbv-DRTrTsyN"}},{"cell_type":"code","source":["train_data = load_json(\"../data/squad_train.json\")\n","valid_data = load_json(\"../data/squad_dev.json\")\n","\n","train_lst = parse_data(train_data)\n","valid_lst = parse_data(valid_data)\n","\n","print(f\"Train Length: {len(train_lst)}\")\n","print(f\"Valid Length: {len(valid_lst)}\")"],"metadata":{"id":"Bw4dj-_YSljb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668498898923,"user_tz":-330,"elapsed":1511,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"7241cf4a-fa95-4f22-e580-3345ed49a4a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of data:  442\n","Data Keys:  dict_keys(['title', 'paragraphs'])\n","Title:  University_of_Notre_Dame\n","Length of data:  48\n","Data Keys:  dict_keys(['title', 'paragraphs'])\n","Title:  Super_Bowl_50\n","a\n","Congress often writes legislation to restrain executive officials to the performance of their duties, as laid out by the laws Congress passes. In INS v. Chadha (1983), the Supreme Court decided (a) The prescription for legislative action in Art. I, § 1—requiring all legislative powers to be vested in a Congress consisting of a Senate and a House of Representatives—and § 7—requiring every bill passed by the House and Senate, before becoming law, to be presented to the president, and, if he disapproves, to be repassed by two-thirds of the Senate and House—represents the Framers' decision that the legislative power of the Federal Government be exercised in accord with a single, finely wrought and exhaustively considered procedure. This procedure is an integral part of the constitutional design for the separation of powers. Further rulings clarified the case; even both Houses acting together cannot override Executive vetos without a 2⁄3 majority. Legislation may always prescribe regulations governing executive officers.\n","Prior to 1871, the government of the United States regularly entered into treaties with Native Americans but the Indian Appropriations Act of March 3, 1871 (ch. 120, 16 Stat. 563) had a rider (25 U.S.C. § 71) attached that effectively ended the President’s treaty making by providing that no Indian nation or tribe shall be acknowledged as an independent nation, tribe, or power with whom the United States may contract by treaty. The federal government continued to provide similar contractual relations with the Indian tribes after 1871 by agreements, statutes, and executive orders.\n","The Constitution of the United States of America provides that the United States Congress has the power \"To coin money\". Laws implementing this power are currently codified at 31 U.S.C. § 5112. Section 5112 prescribes the forms, in which the United States dollars should be issued. These coins are both designated in Section 5112 as \"legal tender\" in payment of debts. The Sacagawea dollar is one example of the copper alloy dollar. The pure silver dollar is known as the American Silver Eagle. Section 5112 also provides for the minting and issuance of other coins, which have values ranging from one cent to 50 dollars. These other coins are more fully described in Coins of the United States dollar.\n","The code itself was patterned so that most control codes were together, and all graphic codes were together, for ease of identification. The first two columns (32 positions) were reserved for control characters.:220, 236 § 8,9) The \"space\" character had to come before graphics to make sorting easier, so it became position 20hex;:237 § 10 for the same reason, many special signs commonly used as separators were placed before digits. The committee decided it was important to support uppercase 64-character alphabets, and chose to pattern ASCII so it could be reduced easily to a usable 64-character set of graphic codes,:228, 237 § 14 as was done in the DEC SIXBIT code. Lowercase letters were therefore not interleaved with uppercase. To keep options available for lowercase letters and other graphics, the special and numeric codes were arranged before the letters, and the letter A was placed in position 41hex to match the draft of the corresponding British standard.:238 § 18 The digits 0–9 were arranged so they correspond to values in binary prefixed with 011, making conversion with binary-coded decimal straightforward.\n","The committee debated the possibility of a shift function (like in ITA2), which would allow more than 64 codes to be represented by a six-bit code. In a shifted code, some character codes determine choices between options for the following character codes. It allows compact encoding, but is less reliable for data transmission as an error in transmitting the shift code typically makes a long part of the transmission unreadable. The standards committee decided against shifting, and so ASCII required at least a seven-bit code.:215, 236 § 4\n","The committee considered an eight-bit code, since eight bits (octets) would allow two four-bit patterns to efficiently encode two digits with binary-coded decimal. However, it would require all data transmission to send eight bits when seven could suffice. The committee voted to use a seven-bit code to minimize costs associated with data transmission. Since perforated tape at the time could record eight bits in one position, it also allowed for a parity bit for error checking if desired.:217, 236 § 5 Eight-bit machines (with octets as the native data type) that did not use parity checking typically set the eighth bit to 0.\n","Under the Antiterrorism and Effective Death Penalty Act of 1996, a state prisoner is ordinarily only allowed one suit for habeas corpus in federal court. If the federal courts refuse to issue a writ of habeas corpus, an execution date may be set. In recent times, however, prisoners have postponed execution through a final round of federal litigation using the Civil Rights Act of 1871 — codified at 42 U.S.C. § 1983 — which allows people to bring lawsuits against state actors to protect their federal constitutional and statutory rights.\n","Present-day statutes from across the nation use the same words and phrases, requiring modern executions to take place within a wall or enclosure to exclude public view. Connecticut General Statute § 54–100 requires death sentences to be conducted in an \"enclosure\" which \"shall be so constructed as to exclude public view.\" Kentucky Revised Statute 431.220 and Missouri Revised Statute § 546.730 contain substantially identical language. New Mexico's former death penalty, since repealed, see N.M. Stat. § 31-14-12, required executions be conducted in a \"room or place enclosed from public view.\" Similarly, a dormant Massachusetts law, see Mass. Gen. Law ch. 279 § 60, required executions to take place \"within an enclosure or building.\" North Carolina General Statute § 15-188 requires death sentences to be executed \"within the walls\" of the penitentiary, as do Oklahoma Statute Title 22 § 1015 and Montana Code § 46-19-103. Ohio Revised Code § 2949.22 requires that \"[t]he enclosure shall exclude public view.\" Similarly, Tennessee Code § 40-23-116 requires \"an enclosure\" for \"strict seclusion and privacy.\" United States Code Title 18 § 3596 and the Code of Federal Regulations 28 CFR 26.4 limit the witnesses permitted at federal executions.\n","The first criminal provision in U.S. copyright law was added in 1897, which established a misdemeanor penalty for \"unlawful performances and representations of copyrighted dramatic and musical compositions\" if the violation had been \"willful and for profit.\" Criminal copyright infringement requires that the infringer acted \"for the purpose of commercial advantage or private financial gain.\" 17 U.S.C. § 506. To establish criminal liability, the prosecutor must first show the basic elements of copyright infringement: ownership of a valid copyright, and the violation of one or more of the copyright holder's exclusive rights. The government must then establish that defendant willfully infringed or, in other words, possessed the necessary mens rea. Misdemeanor infringement has a very low threshold in terms of number of copies and the value of the infringed works.\n","Trade secret misappropriation is different from violations of other intellectual property laws, since by definition trade secrets are secret, while patents and registered copyrights and trademarks are publicly available. In the United States, trade secrets are protected under state law, and states have nearly universally adopted the Uniform Trade Secrets Act. The United States also has federal law in the form of the Economic Espionage Act of 1996 (18 U.S.C. §§ 1831–1839), which makes the theft or misappropriation of a trade secret a federal crime. This law contains two provisions criminalizing two sorts of activity. The first, 18 U.S.C. § 1831(a), criminalizes the theft of trade secrets to benefit foreign powers. The second, 18 U.S.C. § 1832, criminalizes their theft for commercial or economic purposes. (The statutory penalties are different for the two offenses.) In Commonwealth common law jurisdictions, confidentiality and trade secrets are regarded as an equitable right rather than a property right but penalties for theft are roughly the same as the United States.[citation needed]\n","Idealist notions took a strong hold among physicists of the early 20th century confronted with the paradoxes of quantum physics and the theory of relativity. In The Grammar of Science, Preface to the 2nd Edition, 1900, Karl Pearson wrote, \"There are many signs that a sound idealism is surely replacing, as a basis for natural philosophy, the crude materialism of the older physicists.\" This book influenced Einstein's regard for the importance of the observer in scientific measurements[citation needed]. In § 5 of that book, Pearson asserted that \"...science is in reality a classification and analysis of the contents of the mind....\" Also, \"...the field of science is much more consciousness than an external world.\"\n","The Endangered Species Act of 1973 (ESA; 16 U.S.C. § 1531 et seq.) is one of the few dozens of United States environmental laws passed in the 1970s, and serves as the enacting legislation to carry out the provisions outlined in The Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES). The ESA was signed into law by President Richard Nixon on December 28, 1973, it was designed to protect critically imperiled species from extinction as a \"consequence of economic growth and development untempered by adequate concern and conservation.\" The U.S. Supreme Court found that \"the plain intent of Congress in enacting\" the ESA \"was to halt and reverse the trend toward species extinction, whatever the cost.\" The Act is administered by two federal agencies, the United States Fish and Wildlife Service (FWS) and the National Oceanic and Atmospheric Administration (NOAA).\n","The \"Safe Harbor\" agreement is a voluntary agreement between the private landowner and FWS. The landowner agrees to alter the property to benefit or even attract a listed or proposed species in exchange for assurances that the FWS will permit future \"takes\" above a pre-determined level. The policy relies on the \"enhancement of survival\" provision of Section §1539(a)(1)(A). A landowner can have either a \"Safe Harbor\" agreement or an Incidental Take Permit, or both. The policy was developed by the Clinton Administration in 1999.\n","a\n","First, if a Directive's deadline for implementation is not met, the member state cannot enforce conflicting laws, and a citizen may rely on the Directive in such an action (so called \"vertical\" direct effect). So, in Pubblico Ministero v Ratti because the Italian government had failed to implement a Directive 73/173/EEC on packaging and labelling solvents by the deadline, it was estopped from enforcing a conflicting national law from 1963 against Mr Ratti's solvent and varnish business. A member state could \"not rely, as against individuals, on its own failure to perform the obligations which the Directive entails.\" Second, a citizen or company can invoke a Directive, not just in a dispute with a public authority, but in a dispute with another citizen or company. So, in CIA Security v Signalson and Securitel the Court of Justice held that a business called CIA Security could defend itself from allegations by competitors that it had not complied with a Belgian decree from 1991 about alarm systems, on the basis that it had not been notified to the Commission as a Directive required. Third, if a Directive gives expression to a \"general principle\" of EU law, it can be invoked between private non-state parties before its deadline for implementation. This follows from Kücükdeveci v Swedex GmbH & Co KG where the German Civil Code §622 stated that the years people worked under the age of 25 would not count towards the increasing statutory notice before dismissal. Ms Kücükdeveci worked for 10 years, from age 18 to 28, for Swedex GmbH & Co KG before her dismissal. She claimed that the law not counting her years under age 25 was unlawful age discrimination under the Employment Equality Framework Directive. The Court of Justice held that the Directive could be relied on by her because equality was also a general principle of EU law. Third, if the defendant is an emanation of the state, even if not central government, it can still be bound by Directives. In Foster v British Gas plc the Court of Justice held that Mrs Foster was entitled to bring a sex discrimination claim against her employer, British Gas plc, which made women retire at age 60 and men at 65, if (1) pursuant to a state measure, (2) it provided a public service, and (3) had special powers. This could also be true if the enterprise is privatised, as it was held with a water company that was responsible for basic water provision.\n","Train Length: 87541\n","Valid Length: 34711\n"]}]},{"cell_type":"code","source":["train_df = pd.DataFrame(train_lst)\n","valid_df = pd.DataFrame(valid_lst)"],"metadata":{"id":"6XP71oqqQEdB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"Du50jh-5SfU6","executionInfo":{"status":"ok","timestamp":1668499351324,"user_tz":-330,"elapsed":6,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"66c5ef0f-1d5b-4b95-d977-9650717771b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                         id  \\\n","0  5733be284776f41900661182   \n","1  5733be284776f4190066117f   \n","2  5733be284776f41900661180   \n","3  5733be284776f41900661181   \n","4  5733be284776f4190066117e   \n","\n","                                             context  \\\n","0  Architecturally, the school has a Catholic cha...   \n","1  Architecturally, the school has a Catholic cha...   \n","2  Architecturally, the school has a Catholic cha...   \n","3  Architecturally, the school has a Catholic cha...   \n","4  Architecturally, the school has a Catholic cha...   \n","\n","                                            question       label  \\\n","0  To whom did the Virgin Mary allegedly appear i...  [515, 541]   \n","1  What is in front of the Notre Dame Main Building?  [188, 213]   \n","2  The Basilica of the Sacred heart at Notre Dame...  [279, 296]   \n","3                  What is the Grotto at Notre Dame?  [381, 420]   \n","4  What sits on top of the Main Building at Notre...   [92, 126]   \n","\n","                                    answer  \n","0               Saint Bernadette Soubirous  \n","1                a copper statue of Christ  \n","2                        the Main Building  \n","3  a Marian place of prayer and reflection  \n","4       a golden statue of the Virgin Mary  "],"text/html":["\n","  <div id=\"df-c5be0c01-2ebd-49e8-ba04-1197ed119b08\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>label</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5733be284776f41900661182</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>To whom did the Virgin Mary allegedly appear i...</td>\n","      <td>[515, 541]</td>\n","      <td>Saint Bernadette Soubirous</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5733be284776f4190066117f</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is in front of the Notre Dame Main Building?</td>\n","      <td>[188, 213]</td>\n","      <td>a copper statue of Christ</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5733be284776f41900661180</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n","      <td>[279, 296]</td>\n","      <td>the Main Building</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5733be284776f41900661181</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is the Grotto at Notre Dame?</td>\n","      <td>[381, 420]</td>\n","      <td>a Marian place of prayer and reflection</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5733be284776f4190066117e</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What sits on top of the Main Building at Notre...</td>\n","      <td>[92, 126]</td>\n","      <td>a golden statue of the Virgin Mary</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5be0c01-2ebd-49e8-ba04-1197ed119b08')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c5be0c01-2ebd-49e8-ba04-1197ed119b08 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c5be0c01-2ebd-49e8-ba04-1197ed119b08');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["drop_ids_train = filter_large_examples(train_df)\n","train_df.drop(list(drop_ids_train), inplace=True)\n","\n","drop_ids_valid = filter_large_examples(valid_df)\n","valid_df.drop(list(drop_ids_valid), inplace=True)"],"metadata":{"id":"Aiq1TZctTzBy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def preprocess_df(df):\n","    \n","#     def to_lower(text):\n","#         return text.lower()\n","\n","#     df.context = df.context.apply(to_lower)\n","#     df.question = df.question.apply(to_lower)\n","#     df.answer = df.answer.apply(to_lower)"],"metadata":{"id":"7XTlfwZiShq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preprocess_df(train_df)\n","# preprocess_df(valid_df)"],"metadata":{"id":"yEKcvNtgSus6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_text = gather_text_for_vocab([train_df, valid_df])\n","print(\"Number of sentences in dataset: \", len(vocab_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nctPMlObSwp6","executionInfo":{"status":"ok","timestamp":1668499408166,"user_tz":-330,"elapsed":6,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"8f2971a0-6176-47d5-ab0b-958b0af80b8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of sentences in dataset:  118356\n"]}]},{"cell_type":"code","source":["word2idx, idx2word, word_vocab = build_word_vocab(vocab_text)\n","print(\"----------------------------------\")\n","char2idx, char_vocab = build_char_vocab(vocab_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uTTWXDQGTRux","executionInfo":{"status":"ok","timestamp":1668499421309,"user_tz":-330,"elapsed":9946,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"e627efb6-604b-4c83-d81b-8d7febd78573"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["raw-vocab: 109803\n","glove-vocab: 109803\n","vocab-length: 109805\n","word2idx-length: 109804\n","----------------------------------\n","raw-char-vocab: 1400\n","char-vocab-intersect: 230\n","char2idx-length: 231\n"]}]},{"cell_type":"code","source":["train_df['context_ids'] = train_df.context.apply(context_to_ids, word2idx=word2idx)\n","valid_df['context_ids'] = valid_df.context.apply(context_to_ids, word2idx=word2idx)\n","train_df['question_ids'] = train_df.question.apply(question_to_ids, word2idx=word2idx)\n","valid_df['question_ids'] = valid_df.question.apply(question_to_ids, word2idx=word2idx)"],"metadata":{"id":"QVUOepEJTX4q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_err = get_error_indices(train_df, idx2word)\n","valid_err = get_error_indices(valid_df, idx2word)\n","\n","train_df.drop(train_err, inplace=True)\n","valid_df.drop(valid_err, inplace=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CKUqOJvnTh6Y","executionInfo":{"status":"ok","timestamp":1668499498644,"user_tz":-330,"elapsed":44868,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"a864a5ad-f9c1-42f1-cb7b-3a78df268594"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error indices: 920\n","Error indices: 359\n"]}]},{"cell_type":"code","source":["train_label_idx = train_df.apply(index_answer, axis=1, idx2word=idx2word)\n","valid_label_idx = valid_df.apply(index_answer, axis=1, idx2word=idx2word)\n","\n","train_df['label_idx'] = train_label_idx\n","valid_df['label_idx'] = valid_label_idx"],"metadata":{"id":"n6PoYyo-Tl6U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_df), len(valid_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_wzEuX0Ubxf","executionInfo":{"status":"ok","timestamp":1668499541505,"user_tz":-330,"elapsed":12,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"a3f24916-d148-4feb-996a-cc537515183b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(86346, 34080)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["train_df.to_pickle('qanettrain.pkl')\n","valid_df.to_pickle('qanetvalid.pkl')"],"metadata":{"id":"QDDQHLw8Tn_Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","with open('qanetw2id.pickle','wb') as handle:\n","    pickle.dump(word2idx, handle)\n","\n","with open('qanetc2id.pickle','wb') as handle:\n","    pickle.dump(char2idx, handle)"],"metadata":{"id":"E2GBFSA-UeYi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Data Loader"],"metadata":{"id":"7lSkQS6bUlya"}},{"cell_type":"code","source":["with open('qanetw2id.pickle','rb') as handle:\n","    word2idx = pickle.load(handle)\n","with open('qanetc2id.pickle','rb') as handle:\n","    char2idx = pickle.load(handle)"],"metadata":{"id":"1jrFUQrYUhCn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_pickle('qanettrain.pkl')\n","valid_df = pd.read_pickle('qanetvalid.pkl')"],"metadata":{"id":"0SyKhqLpVRNG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idx2word = {v:k for k,v in word2idx.items()}"],"metadata":{"id":"8dw9N8-vVTDB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SQuAD:\n","    def __init__(self, data, batch_size):\n","        self.batch_size = batch_size\n","        data = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\n","        self.data = data\n","        \n","        \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def make_char_vector(self, max_sent_len, sentence, max_word_len=16):\n","        \n","        char_vec = torch.zeros(max_sent_len, max_word_len).type(torch.LongTensor)\n","        \n","        for i, word in enumerate(nlp(sentence, disable=['parser','tagger','ner'])):\n","            for j, ch in enumerate(word.text):\n","                if j == max_word_len:\n","                    break\n","                char_vec[i][j] = char2idx.get(ch, 0)\n","        \n","        return char_vec     \n","    \n","    def get_span(self, text):\n","\n","        text = nlp(text, disable=['parser','tagger','ner'])\n","        span = [(w.idx, w.idx+len(w.text)) for w in text]\n","\n","        return span\n","\n","    \n","    def __iter__(self):\n","        \n","        for batch in self.data:\n","            \n","            spans = []\n","            ctx_text = []\n","            answer_text = []\n","            \n","             \n","            for ctx in batch.context:\n","                ctx_text.append(ctx)\n","                spans.append(self.get_span(ctx))\n","            \n","            for ans in batch.answer:\n","                answer_text.append(ans)\n","                \n","            max_context_len = max([len(ctx) for ctx in batch.context_ids])\n","            padded_context = torch.LongTensor(len(batch), max_context_len).fill_(1)\n","            \n","            for i, ctx in enumerate(batch.context_ids):\n","                padded_context[i, :len(ctx)] = torch.LongTensor(ctx)\n","                \n","            max_word_ctx = 16\n","          \n","            char_ctx = torch.zeros(len(batch), max_context_len, max_word_ctx).type(torch.LongTensor)\n","            for i, context in enumerate(batch.context):\n","                char_ctx[i] = self.make_char_vector(max_context_len, context)\n","            \n","            max_question_len = max([len(ques) for ques in batch.question_ids])\n","            padded_question = torch.LongTensor(len(batch), max_question_len).fill_(1)\n","            \n","            for i, ques in enumerate(batch.question_ids):\n","                padded_question[i, :len(ques)] = torch.LongTensor(ques)\n","                \n","            max_word_ques = 16\n","            \n","            char_ques = torch.zeros(len(batch), max_question_len, max_word_ques).type(torch.LongTensor)\n","            for i, question in enumerate(batch.question):\n","                char_ques[i] = self.make_char_vector(max_question_len, question)\n","            \n","              \n","            label = torch.LongTensor(list(batch.label_idx))\n","            ids = list(batch.id)\n","            \n","            yield (padded_context, padded_question, char_ctx, char_ques, label, ctx_text, answer_text, ids)\n","            \n","         "],"metadata":{"id":"o51hnOh8VUT5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = SQuAD(train_df, 12)\n","valid_dataset = SQuAD(valid_df, 12)     "],"metadata":{"id":"r5Y5cHajVi3x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#QANet"],"metadata":{"id":"Y8Fivjf1gRO-"}},{"cell_type":"markdown","source":["##Word Level Embedding"],"metadata":{"id":"XDZUtZA7g7yy"}},{"cell_type":"code","source":["def get_glove_embedding():\n","    glove_dict = {}\n","    with open(\"../GloVe/glove.840B.300d.txt\", \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            lst = line.split(' ')\n","            word = lst[0]\n","            vector = np.asarray(lst[1:], dtype=\"float32\")\n","            glove_dict[word] = vector\n","    \n","    f.close()\n","    return glove_dict\n"],"metadata":{"id":"mc2UwKQJfUUF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["glove_dict = get_glove_embedding()"],"metadata":{"id":"NnylRUNJjb-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_weight_matrix(glove_dict):\n","    weight_matrix = np.zeros((len(word_vocab), 300))\n","    num_words = 0\n","    for i, word in enumerate(word_vocab):\n","        try:\n","            weight_matrix[i] = glove_dict[word]\n","            num_words += 1\n","        except:\n","            pass\n","\n","    return weight_matrix, num_words"],"metadata":{"id":"HYaTq7ZckxOb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weight_matrix, num_words = get_weight_matrix(glove_dict)\n","num_words"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1G9ro0eCl4RY","executionInfo":{"status":"ok","timestamp":1668504143786,"user_tz":-330,"elapsed":7,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"4072bab4-82e3-4e6c-d708-cde4927ef587"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["90777"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["np.save(\"qanetglove.npy\", weight_matrix)"],"metadata":{"id":"58poU7qCmEeS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Character Level Embedding (Depthwise Separable Convolutions)"],"metadata":{"id":"-zfNjMXEn1aE"}},{"cell_type":"code","source":["class DepthwiseSeparableConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, dim=1):\n","        super(DepthwiseSeparableConv, self).__init__()\n","        self.dim = dim\n","\n","        self.depthwise = nn.Conv1d(in_channels, in_channels, kernel_size, padding=kernel_size // 2, groups=in_channels,\n","                                   bias=False)\n","        self.pointwise = nn.Conv1d(in_channels, out_channels, 1, bias=True)\n","\n","        if dim == 2:\n","            self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, padding=kernel_size // 2, groups=in_channels,\n","                                   bias=False)\n","            self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=True)\n","\n","\n","    def forward(self, x):\n","        if self.dim == 1:\n","            x = self.depthwise(x.transpose(1, 2))\n","            x = self.pointwise(x)\n","            x = x.transpose(1, 2)\n","        else:\n","            x = self.depthwise(x)\n","            x = self.pointwise(x)\n","\n","        return x"],"metadata":{"id":"EbbKKaNNnyo8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Highway Network"],"metadata":{"id":"numlMfvs-J8r"}},{"cell_type":"code","source":["# Highway Network\n","class Highway(nn.Module):\n","    def __init__(self, size, num_layers):\n","        super(Highway, self).__init__()\n","        self.num_layers = num_layers\n","        self.nonlinear = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n","        self.linear = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n","        self.gate = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n","\n","    def forward(self, x):\n","        for i in range(self.num_layers):\n","            nonlinear = F.relu(self.nonlinear[i](x))\n","            linear = self.linear[i](x)\n","            gate = torch.sigmoid(self.gate[i](x))\n","            x = gate * nonlinear + (1 - gate) * linear\n","        return x"],"metadata":{"id":"tZ6FrGBL5S6A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Embedding Layer"],"metadata":{"id":"odJXY194-Oc8"}},{"cell_type":"code","source":["# Embedding Layer\n","class Embedding(nn.Module):\n","    def __init__(self, char_vocab_size, char_embed_size, char_out_size, device, dropout=0.1):\n","        super(Embedding, self).__init__()\n","        self.word_embed_size = None\n","        self.char_embed_size = char_embed_size\n","        self.char_out_size = char_out_size\n","        self.dropout = dropout\n","        self.device = device\n","\n","        self.word_embed = self.get_word_embed()\n","        self.char_embed = nn.Embedding(char_vocab_size, char_embed_size)\n","        self.char_conv2d = DepthwiseSeparableConv(char_embed_size, char_embed_size, char_out_size, dim=2)\n","\n","        self.highway = Highway(self.word_embed_size + char_embed_size, 2)\n","\n","    def get_word_embed(self):\n","        weights_matrix = np.load('qanetglove.npy')\n","        num_embeddings, embedding_dim = weights_matrix.shape\n","        self.word_embed_size = embedding_dim\n","        word_embed = nn.Embedding.from_pretrained(torch.FloatTensor(weights_matrix), freeze=True).to(self.device)\n","        return word_embed\n","\n","    def forward(self, x, char_x):\n","        x = self.word_embed(x)\n","        x = F.dropout(x, p=self.dropout)\n","        char_x = self.char_embed(char_x)\n","\n","        char_x = F.dropout(char_x.permute(0, 3, 1, 2), p=self.dropout)\n","        char_x = F.relu(self.char_conv2d(char_x))\n","        char_x = torch.max(char_x, dim=3)[0]\n","        char_x = char_x.permute(0, 2, 1)\n","        x = torch.cat([x, char_x], dim=2)\n","        x = self.highway(x)\n","        return x"],"metadata":{"id":"ewP8AbVN5SvZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Multi-head Attention"],"metadata":{"id":"ahFr5SETJzsH"}},{"cell_type":"code","source":["# Multi-Head Self-Attention\n","class MultiHeadSelfAttention(nn.Module):\n","    def __init__(self, embed_size, num_heads, dropout=0.1):\n","        super(MultiHeadSelfAttention, self).__init__()\n","        self.embed_size = embed_size\n","        self.num_heads = num_heads\n","        self.head_size = embed_size // num_heads\n","        self.dropout = dropout\n","\n","        self.W_Q = nn.Linear(embed_size, embed_size)\n","        self.W_K = nn.Linear(embed_size, embed_size)\n","        self.W_V = nn.Linear(embed_size, embed_size)\n","\n","        self.W_O = nn.Linear(embed_size, embed_size)\n","\n","    def forward(self, x, mask):\n","        Q = self.W_Q(x)\n","        K = self.W_K(x)\n","        V = self.W_V(x)\n","\n","        Q = Q.view(-1, Q.size(1), self.num_heads, int(self.embed_size / self.num_heads)).permute(0, 2, 1, 3)\n","        K = K.view(-1, K.size(1), self.num_heads, int(self.embed_size / self.num_heads)).permute(0, 2, 1, 3)\n","        V = V.view(-1, V.size(1), self.num_heads, int(self.embed_size / self.num_heads)).permute(0, 2, 1, 3)\n","\n","        K_T = K.permute(0, 1, 3, 2)\n","        attention = torch.matmul(Q, K_T) / np.sqrt(self.embed_size / self.num_heads)\n","        # print(x.size())\n","        attention = attention - 1e30 * (1 - mask[:, None, None, :])\n","        attention = F.softmax(attention, dim=-1)\n","        attention = F.dropout(attention, p=self.dropout)\n","\n","        x = torch.matmul(attention, V)\n","        x = x.permute(0, 2, 1, 3).contiguous()\n","        x = x.view(-1, x.size(1), self.embed_size)\n","        x = self.W_O(x)\n","        return x"],"metadata":{"id":"L5293ga1-SSf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Positional Encoder"],"metadata":{"id":"B7NUVLG1KAFD"}},{"cell_type":"code","source":["# Positional Encoder\n","class PositionalEncoder(nn.Module):\n","    def __init__(self, embed_size, device, dropout=0.1):\n","        super(PositionalEncoder, self).__init__()\n","        self.dropout = dropout\n","        self.embed_size = embed_size\n","        self.device = device\n","        self.W_P = nn.Linear(embed_size, embed_size)\n","\n","    def forward(self, x):\n","        batch_size, seq_len, embed_size = x.size()\n","        position = torch.arange(seq_len, dtype=torch.float32).to(self.device)\n","        position = position.unsqueeze(0).expand(batch_size, seq_len)\n","        position = position.unsqueeze(2).expand(batch_size, seq_len, embed_size)\n","        # print(position.size())\n","        position = position / torch.pow(10000, torch.arange(0, embed_size, dtype=torch.float32, step=1).to(self.device) / embed_size)\n","        position[:, :, 0::2] = torch.sin(position[:, :, 0::2])\n","        position[:, :, 1::2] = torch.cos(position[:, :, 1::2])\n","        x = x + position\n","        x = self.W_P(x)\n","        x = F.dropout(x, p=self.dropout)\n","        return x"],"metadata":{"id":"O4HYDtcFKDdZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Context-Query Attention Layer"],"metadata":{"id":"anqNc6SMnkW8"}},{"cell_type":"code","source":["class BiAttention(nn.Module):\n","    def __init__(self, embed_size, dropout=0.1):\n","        super(ContextQueryAttention, self).__init__()\n","        self.dropout = dropout\n","        self.W_O = nn.Linear(3*embed_size, 1)\n","\n","    def forward(self, C, Q, C_mask, Q_mask):\n","        C_len = C_mask.size(1)\n","        Q_len = Q_mask.size(1)\n","\n","        C_mask = C_mask[:, :, None]\n","        Q_mask = Q_mask[:, None, :]\n","\n","\n","        C_ = C.unsqueeze(2).expand(-1, -1, Q_len, -1)\n","        Q_ = Q.unsqueeze(1).expand(-1, C_len, -1, -1)\n","        element_wise_product = C_ * Q_\n","        S = torch.cat([C_, Q_, element_wise_product], dim=-1)\n","        S = self.W_O(S).squeeze(-1)\n","        S = S - 1e30 * (1 - C_mask) - 1e30 * (1 - Q_mask)\n","        S_C = F.softmax(S, dim=2)\n","        S_C = F.dropout(S_C, p=self.dropout)\n","        S_Q = F.softmax(S, dim=1)\n","        S_Q = F.dropout(S_Q, p=self.dropout)\n","\n","        C2Q = torch.matmul(S_C, Q)\n","        Q2C = torch.matmul(torch.matmul(S_C, S_Q.permute(0, 2, 1)), C)\n","\n","        out = torch.cat([C, C2Q, C * C2Q, C * Q2C], dim=-1)\n","\n","        return out"],"metadata":{"id":"igoglIdGJ5Z6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, hidden_size, dropout=0.1, num_heads=8):\n","        super(MultiHeadAttention, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_heads = num_heads\n","        self.dropout = dropout\n","        self.head_size = int(hidden_size / num_heads)\n","        self.query = nn.Linear(hidden_size, hidden_size)\n","        self.key = nn.Linear(hidden_size, hidden_size)\n","        self.value = nn.Linear(hidden_size, hidden_size)\n","        self.dense = nn.Linear(2*hidden_size, hidden_size)\n","\n","    def transpose_for_scores(self, x):\n","        new_x_shape = x.size()[:-1] + (self.num_heads, self.head_size)\n","        x = x.view(*new_x_shape)\n","        return x.permute(0, 2, 1, 3)\n","\n","    def forward(self, hidden_states, memory, attention_mask):\n","        mixed_query_layer = self.query(hidden_states)\n","        mixed_key_layer = self.key(memory)\n","        mixed_value_layer = self.value(memory)\n","\n","        query_layer = self.transpose_for_scores(mixed_query_layer)\n","        key_layer = self.transpose_for_scores(mixed_key_layer)\n","        value_layer = self.transpose_for_scores(mixed_value_layer)\n","\n","        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n","        attention_scores = attention_scores / math.sqrt(self.head_size)\n","        attention_scores = attention_scores - 1e30 * (1 - attention_mask[:, None, None, :])\n","\n","        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n","        attention_probs = nn.Dropout(self.dropout)(attention_probs)\n","\n","        context_layer = torch.matmul(attention_probs, value_layer)\n","        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n","        new_context_layer_shape = context_layer.size()[:-2] + (self.hidden_size,)\n","        context_layer = context_layer.view(*new_context_layer_shape)\n","\n","        ou = torch.cat([hidden_states, context_layer], dim=-1)\n","\n","        attention_output = self.dense(ou)\n","        return F.relu(attention_output)"],"metadata":{"id":"nDHwFzlRbLDr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Encoder Block"],"metadata":{"id":"_StwrmwgJ3jt"}},{"cell_type":"code","source":["# Encoder Block\n","class EncoderBlock(nn.Module):\n","    def __init__(self, embed_size, num_heads, num_conv_layers, conv_kernel_size, device, dropout=0.1):\n","        super(EncoderBlock, self).__init__()\n","        self.embed_size = embed_size\n","        self.num_conv_layers = num_conv_layers\n","        self.num_heads = num_heads\n","        self.conv_kernel_size = conv_kernel_size\n","        self.dropout = dropout\n","\n","        self.self_attention = MultiHeadSelfAttention(embed_size, num_heads, dropout)\n","        self.self_attention_norm = nn.LayerNorm(embed_size)\n","\n","        self.position_encoder = PositionalEncoder(embed_size, device, dropout)\n","        self.position_encoder_norm = nn.LayerNorm(embed_size)\n","\n","        self.conv_layers = nn.ModuleList([DepthwiseSeparableConv(embed_size, embed_size, conv_kernel_size, dim=1) for _ in range(num_conv_layers)])\n","        self.conv_norm = nn.ModuleList([nn.LayerNorm(embed_size) for _ in range(num_conv_layers)])\n","\n","        self.feed_forward = nn.Linear(embed_size, embed_size)\n","        self.feed_forward_norm = nn.LayerNorm(embed_size)\n","\n","    def forward(self, x, mask):\n","        position_encoder = self.position_encoder(x)\n","        residual = x\n","        x = self.position_encoder_norm(position_encoder)\n","        for i in range(self.num_conv_layers):\n","            x = F.relu(self.conv_layers[i](x), inplace=False)\n","            x += residual\n","            if (i+1)%2 == 0:\n","                x = F.dropout(x, p=self.dropout)\n","            residual = x\n","            x = self.conv_norm[i](x)\n","\n","        x = self.self_attention(x, mask)\n","        x = F.dropout(x+residual, p=self.dropout)\n","        residual = x\n","        x = self.self_attention_norm(x)\n","\n","        x = self.feed_forward(x)\n","        x = F.dropout(x+residual, p=self.dropout)\n","        return x\n","\n"],"metadata":{"id":"4Bj2DCYDE41Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Ouput Layer"],"metadata":{"id":"K0fTWh3Psvgg"}},{"cell_type":"code","source":["# Output Layer\n","class OutputLayer(nn.Module):\n","    def __init__(self, embed_size, dropout=0.1):\n","        super(OutputLayer, self).__init__()\n","        self.dropout = dropout\n","        self.W_1 = nn.Linear(2*embed_size, 1, bias=False)\n","        self.W_2 = nn.Linear(2*embed_size, 1, bias=False)\n","\n","    def forward(self, M1, M2, M3, C_mask):\n","        pred_start = torch.cat([M1, M2], dim=-1)\n","        pred_start = self.W_1(pred_start).squeeze(-1)\n","        pred_start = pred_start - 1e30 * (1 - C_mask)\n","\n","        pred_end = torch.cat([M1, M3], dim=-1)\n","        pred_end = self.W_2(pred_end).squeeze(-1)\n","        pred_end = pred_end - 1e30 * (1 - C_mask)\n","\n","        return pred_start, pred_end"],"metadata":{"id":"nI1nQ5atszDB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Model"],"metadata":{"id":"wNG-v5WGysyu"}},{"cell_type":"code","source":["#QANet Model\n","class QANet(nn.Module):\n","    def __init__(self, char_vocab_size, char_embed_size, word_embed_size, embed_size, num_heads, conv_kernel_size, device, dropout=0.1):\n","        super(QANet, self).__init__()\n","        self.char_embed_size = char_embed_size\n","        self.embed_size = embed_size\n","        self.dropout = dropout\n","        print(char_embed_size)\n","\n","        self.embedding = Embedding(char_vocab_size, char_embed_size, conv_kernel_size, device, dropout)\n","        self.ctx_resizer = DepthwiseSeparableConv(char_embed_size+word_embed_size, embed_size, 5)\n","        self.query_resizer = DepthwiseSeparableConv(char_embed_size+word_embed_size, embed_size, 5)\n","\n","        self.embedding_encoder = EncoderBlock(embed_size, num_heads, 4, 5, device, dropout)\n","\n","        self.context_query_attention = ContextQueryAttention(embed_size, dropout)\n","        self.cqa_resizer = DepthwiseSeparableConv(4*embed_size, embed_size, 5)\n","\n","        self.model_encoder_layers = nn.ModuleList([EncoderBlock(embed_size, num_heads, 2, 5, device, dropout) for _ in range(7)])\n","        self.output_layer = OutputLayer(embed_size, dropout)\n","\n","        self.device = device\n","\n","    def forward(self, C_word, Q_word, C_char, Q_char):\n","        C_mask = (C_word > 0).float()\n","        Q_mask = (Q_word > 0).float()\n","\n","        Q_d = torch.zeros_like(C_mask)\n","        Q_d[:, :Q_mask.size(1)] = Q_mask\n","        Q_mask = Q_d\n","\n","        C_embed = self.embedding(C_word, C_char)\n","        Q_embed = self.embedding(Q_word, Q_char)\n","\n","        C = self.ctx_resizer(C_embed)\n","        Q = self.query_resizer(C_embed)\n","\n","        C = self.embedding_encoder(C, C_mask)\n","        Q = self.embedding_encoder(Q, Q_mask)\n","\n","        CQA = self.context_query_attention(C, Q, C_mask, Q_mask)\n","        M1 = self.cqa_resizer(CQA)\n","\n","        for layer in self.model_encoder_layers:\n","            M1 = layer(M1, C_mask)\n","\n","        M2 = M1\n","\n","        for layer in self.model_encoder_layers:\n","            M2 = layer(M2, C_mask)\n","\n","        M3 = M2\n","\n","        for layer in self.model_encoder_layers:\n","            M3 = layer(M3, C_mask)\n","\n","        pred_start, pred_end = self.output_layer(M1, M2, M3, C_mask)\n","        return pred_start, pred_end"],"metadata":{"id":"QW09WmSnsy9B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Training"],"metadata":{"id":"p2oCQIqG8Hww"}},{"cell_type":"code","source":["# Training\n","CHAR_VOCAB_SIZE = len(char2idx)\n","CHAR_EMBED_SIZE = 200\n","WORD_EMBED_SIZE = 300\n","KERNEL_SIZE = 5\n","EMBED_SIZE = 128\n","NUM_HEADS = 8\n","\n","device = torch.device('cpu')\n","model = QANet(CHAR_VOCAB_SIZE, CHAR_EMBED_SIZE, WORD_EMBED_SIZE, EMBED_SIZE, NUM_HEADS, KERNEL_SIZE, device).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), betas=(0.8, 0.999), eps=1e-7, weight_decay=3e-7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2WfcVMRJsy66","executionInfo":{"status":"ok","timestamp":1668652330193,"user_tz":-330,"elapsed":625,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"c77521b2-0b7e-46db-dfde-62aa7b8c88c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["200\n"]}]},{"cell_type":"code","source":["def train(model, train_dataset):\n","    print('Training...')\n","    model.train()\n","    total_loss = 0\n","    batch_count = 0\n","    for batch in tqdm(train_dataset):\n","        if batch_count%500 == 0:\n","            print('Batch: {}'.format(batch_count))\n","\n","        batch_count += 1\n","\n","        context, question, char_context, char_question, label, context_text, answer, ids = batch\n","\n","        pred_start, pred_end = model(context, question, char_context, char_question)\n","\n","        loss = F.cross_entropy(pred_start, label[:,0]) + F.cross_entropy(pred_end, label[:,1])\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        total_loss += loss.item()\n","\n","    return total_loss/len(train_dataset)"],"metadata":{"id":"6pJqIEWVsy4C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(model, val_dataset):\n","    print('Validating...')\n","    model.eval()\n","    valid_loss = 0\n","    batch_count = 0\n","    predictions = {}\n","    for batch in tqdm(val_dataset):\n","        if batch_count%500 == 0:\n","            print('Batch: {}'.format(batch_count))\n","\n","        batch_count += 1\n","\n","        context, question, char_context, char_question, label, context_text, answer, ids = batch\n","        context, question, char_context, char_question, label = context.to(device), question.to(device), char_context.to(device), char_question.to(device), label.to(device)\n","\n","        with torch.no_grad():\n","            pred_start, pred_end = model(context, question, char_context, char_question)\n","\n","            loss = F.nll_loss(pred_start, label[:,0]) + F.nll_loss(pred_end, label[:,1])\n","            valid_loss += loss.item()\n","\n","            batch_size, seq_len = pred_start.shape\n","            ls = nn.LogSoftmax(dim=-1)\n","            mask = (torch.ones(seq_len, seq_len)*float('-inf')).to(device).tril(-1).unsqueeze(0).expand(batch_size, -1, -1)\n","            score = ls(pred_start).unsqueeze(2) + ls(pred_end).unsqueeze(1) + mask\n","            score, start_idx = score.max(dim=1)\n","            score, end_idx = score.max(dim=1)\n","            start_idx = start_idx.gather(1, end_idx.unsqueeze(1)).squeeze(1)\n","\n","            for i in range(batch_size):\n","                id = ids[i]\n","                pred = context[i][start_idx[i]:end_idx[i]+1]\n","                pred = ' '.join([idx2word[idx.item()] for idx in pred])\n","                predictions[id] = pred\n","\n","    em, f1 = evaluate(predictions)\n","    return valid_loss/len(val_dataset), em, f1"],"metadata":{"id":"I-bR1xIBsy1g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalize_answer(s):\n","    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","    def remove_articles(text):\n","        regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n","        return re.sub(regex, ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","\n","def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n","    scores_for_ground_truths = []\n","    for ground_truth in ground_truths:\n","        score = metric_fn(prediction, ground_truth)\n","        scores_for_ground_truths.append(score)\n","    return max(scores_for_ground_truths)\n","\n","\n","def f1_score(prediction, ground_truth):\n","    prediction_tokens = normalize_answer(prediction).split()\n","    ground_truth_tokens = normalize_answer(ground_truth).split()\n","    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n","    num_same = sum(common.values())\n","    if len(prediction_tokens) == 0 or len(ground_truth_tokens) == 0:\n","        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n","        return int(prediction_tokens == ground_truth_tokens)\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(prediction_tokens)\n","    recall = 1.0 * num_same / len(ground_truth_tokens)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1\n","\n","\n","def exact_match_score(prediction, ground_truth):\n","    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n","\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs\n","\n","\n","def evaluate(predictions):\n","    with open('../data/squad_dev.json') as f:\n","        dataset_json = json.load(f)\n","\n","    dataset = dataset_json['data']\n","    f1 = exact_match = total = 0\n","    for article in dataset:\n","        for paragraph in article['paragraphs']:\n","            for qa in paragraph['qas']:\n","                total += 1\n","                if qa['id'] not in predictions:\n","                    continue\n","                ground_truths = list(map(lambda x: x['text'], qa['answers']))\n","                prediction = predictions[qa['id']]\n","                exact_match += metric_max_over_ground_truths(exact_match_score, prediction, ground_truths)\n","                f1 += metric_max_over_ground_truths(f1_score, prediction, ground_truths)\n","\n","    exact_match = 100.0 * exact_match / total\n","    f1 = 100.0 * f1 / total\n","\n","    return exact_match, f1"],"metadata":{"id":"A298AbSfAs3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.autograd.set_detect_anomaly(True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VMi6zbt9RoAc","executionInfo":{"status":"ok","timestamp":1668652331464,"user_tz":-330,"elapsed":650,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"c2a720fc-bcfc-4dc8-8671-64fb21e59ab7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7ff32d3e2090>"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["train_losses = []\n","valid_losses = []\n","valid_em = []\n","valid_f1 = []\n","epochs = 10\n","\n","for epoch in range(epochs):\n","    start_time = time.time()\n","\n","    train_loss = train(model, train_dataset)\n","    valid_loss, em, f1 = validate(model, valid_dataset)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    valid_em.append(em)\n","    valid_f1.append(f1)\n","\n","    print('Epoch: {} | Time: {}m {}s'.format(epoch + 1, epoch_mins, epoch_secs))\n","    print('\\tTrain Loss: {:.3f}'.format(train_loss))\n","    print('\\t Val. Loss: {:.3f} |  Val. EM: {:.2f}% |  Val. F1: {:.2f}%'.format(valid_loss, em, f1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"bWLOiGeQC1-r","executionInfo":{"status":"error","timestamp":1668652339027,"user_tz":-330,"elapsed":7566,"user":{"displayName":"Kavin R V 19163","userId":"16623310270923564772"}},"outputId":"c9397563-7b68-48d3-8426-8f945183c948"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training...\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/7196 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Batch: 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py:175: UserWarning: Error detected in ReluBackward0. Traceback of forward call that caused the error:\n","  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 787, in inner\n","    self.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n","    yielded = next(result)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n","    yielded = next(result)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n","    user_expressions, allow_stdin,\n","  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n","    yielded = next(result)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n","    raw_cell, store_history, silent, shell_futures)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n","    interactivity=interactivity, compiler=compiler, result=result)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-43-50bd5dc01c44>\", line 10, in <module>\n","    train_loss = train(model, train_dataset)\n","  File \"<ipython-input-39-97ba7a64a09e>\", line 14, in train\n","    pred_start, pred_end = model(context, question, char_context, char_question)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"<ipython-input-31-c1739961a101>\", line 55, in forward\n","    M3 = layer(M3, C_mask)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"<ipython-input-15-356b265a4d50>\", line 28, in forward\n","    x = F.relu(self.conv_layers[i](x), inplace=False)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1457, in relu\n","    result = torch.relu(input)\n"," (Triggered internally at  ../torch/csrc/autograd/python_anomaly_mode.cpp:102.)\n","  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\r  0%|          | 0/7196 [00:08<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-50bd5dc01c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-39-97ba7a64a09e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [12, 253, 128]], which is output 0 of ReluBackward0, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"]}]},{"cell_type":"code","source":["torch.arange(0, 10, dtype=torch.float32, step=2)"],"metadata":{"id":"2L95H0tIDHGJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"akHEfvr0Kvj7"},"execution_count":null,"outputs":[]}]}